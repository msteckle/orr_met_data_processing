{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed7ec8-3283-492b-9415-582badd4b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for TOWA_2017-2022_gapfilled-qc:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210288 entries, 20170101050000 to 20230101044500\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   TempC_015m      210288 non-null  float32\n",
      " 1   TempC_030m      210288 non-null  float32\n",
      " 2   RelHum_015m     210288 non-null  float32\n",
      " 3   AbsHum_015m     210288 non-null  float32\n",
      " 4   WSpdMph_015m    210288 non-null  float32\n",
      " 5   WSpdMph_030m    210288 non-null  float32\n",
      " 6   PkWSpdMph_015m  210288 non-null  float32\n",
      " 7   PkWSpdMph_030m  210288 non-null  float32\n",
      " 8   VSSpdMph_015m   210139 non-null  float32\n",
      " 9   VSSpdMph_030m   210163 non-null  float32\n",
      " 10  BarPresMb_015m  210150 non-null  float32\n",
      " 11  Sigma_015m      210076 non-null  float32\n",
      " 12  Sigma_030m      210269 non-null  float32\n",
      " 13  SigPhi_015m     210164 non-null  float32\n",
      " 14  SigPhi_030m     210164 non-null  float32\n",
      " 15  WDir_015m       210288 non-null  float32\n",
      " 16  WDir_030m       210288 non-null  float32\n",
      " 17  PrecipIn_015m   210288 non-null  float32\n",
      "dtypes: float32(18)\n",
      "memory usage: 16.0 MB\n",
      "None\n",
      "DataFrame for TOWB_2017-2022_gapfilled-qc:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210288 entries, 20170101050000 to 20230101044500\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   TempC_015m        210288 non-null  float32\n",
      " 1   TempC_030m        210288 non-null  float32\n",
      " 2   RelHum_015m       210288 non-null  float32\n",
      " 3   WSpdMph_015m      210288 non-null  float32\n",
      " 4   WSpdMph_030m      210288 non-null  float32\n",
      " 5   PkWSpdMph_015m    210288 non-null  float32\n",
      " 6   PkWSpdMph_030m    210288 non-null  float32\n",
      " 7   VSSpdMph_015m     190201 non-null  float32\n",
      " 8   VSSpdMph_030m     183145 non-null  float32\n",
      " 9   SolarRadWm2_015m  0 non-null       float32\n",
      " 10  BarPresMb_015m    204346 non-null  float32\n",
      " 11  Sigma_015m        210288 non-null  float32\n",
      " 12  Sigma_030m        210288 non-null  float32\n",
      " 13  SigPhi_015m       190275 non-null  float32\n",
      " 14  SigPhi_030m       185110 non-null  float32\n",
      " 15  WDir_015m         210288 non-null  float32\n",
      " 16  WDir_030m         210288 non-null  float32\n",
      " 17  PrecipIn_015m     210288 non-null  float32\n",
      "dtypes: float32(18)\n",
      "memory usage: 16.0 MB\n",
      "None\n",
      "DataFrame for TOWD_2017-2022_gapfilled-qc:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210288 entries, 20170101050000 to 20230101044500\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   TempC_015m        210288 non-null  float32\n",
      " 1   TempC_002m        210288 non-null  float32\n",
      " 2   TempC_035m        210288 non-null  float32\n",
      " 3   TempC_060m        210288 non-null  float32\n",
      " 4   RelHum_015m       210288 non-null  float32\n",
      " 5   RelHum_002m       210288 non-null  float32\n",
      " 6   AbsHum_015m       210288 non-null  float32\n",
      " 7   AbsHum_002m       210288 non-null  float32\n",
      " 8   WSpdMph_015m      187465 non-null  float32\n",
      " 9   WSpdMph_035m      210288 non-null  float32\n",
      " 10  WSpdMph_060m      210288 non-null  float32\n",
      " 11  PkWSpdMph_015m    187513 non-null  float32\n",
      " 12  PkWSpdMph_035m    210288 non-null  float32\n",
      " 13  PkWSpdMph_060m    210288 non-null  float32\n",
      " 14  VSSpdMph_015m     209809 non-null  float32\n",
      " 15  VSSpdMph_060m     209636 non-null  float32\n",
      " 16  SolarRadWm2_002m  206286 non-null  float32\n",
      " 17  BarPresMb_015m    210211 non-null  float32\n",
      " 18  BarPresMb_002m    210211 non-null  float32\n",
      " 19  Sigma_015m        204331 non-null  float32\n",
      " 20  Sigma_035m        210288 non-null  float32\n",
      " 21  Sigma_060m        210288 non-null  float32\n",
      " 22  SigPhi_015m       210209 non-null  float32\n",
      " 23  SigPhi_060m       210209 non-null  float32\n",
      " 24  WDir_015m         187498 non-null  float32\n",
      " 25  WDir_035m         210288 non-null  float32\n",
      " 26  WDir_060m         210288 non-null  float32\n",
      " 27  PrecipIn_002m     210288 non-null  float32\n",
      "dtypes: float32(28)\n",
      "memory usage: 24.1 MB\n",
      "None\n",
      "DataFrame for TOWF_2017-2022_gapfilled-qc:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210288 entries, 20170101050000 to 20230101044500\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   TempC_010m        181609 non-null  float32\n",
      " 1   RelHum_010m       181393 non-null  float32\n",
      " 2   AbsHum_010m       179727 non-null  float32\n",
      " 3   WSpdMph_010m      181804 non-null  float32\n",
      " 4   PkWSpdMph_010m    181780 non-null  float32\n",
      " 5   VSSpdMph_010m     181193 non-null  float32\n",
      " 6   SolarRadWm2_010m  181546 non-null  float32\n",
      " 7   BarPresMb_010m    179604 non-null  float32\n",
      " 8   Sigma_010m        181224 non-null  float32\n",
      " 9   SigPhi_010m       181490 non-null  float32\n",
      " 10  WDir_010m         181862 non-null  float32\n",
      " 11  PrecipIn_010m     181886 non-null  float32\n",
      "dtypes: float32(12)\n",
      "memory usage: 11.2 MB\n",
      "None\n",
      "DataFrame for TOWS_2017-2022_gapfilled-qc:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210288 entries, 20170101050000 to 20230101044500\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   TempC_025m      210131 non-null  float32\n",
      " 1   WSpdMph_025m    210132 non-null  float32\n",
      " 2   PkWSpdMph_025m  210127 non-null  float32\n",
      " 3   VSSpdMph_025m   210186 non-null  float32\n",
      " 4   Sigma_025m      210159 non-null  float32\n",
      " 5   SigPhi_025m     210186 non-null  float32\n",
      " 6   WDir_025m       210132 non-null  float32\n",
      "dtypes: float32(7)\n",
      "memory usage: 7.2 MB\n",
      "None\n",
      "DataFrame for TOWY_2017-2022_gapfilled-qc:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 210288 entries, 20170101050000 to 20230101044500\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   TempC_033m        210288 non-null  float32\n",
      " 1   TempC_015m        210288 non-null  float32\n",
      " 2   RelHum_015m       210288 non-null  float32\n",
      " 3   WSpdMph_033m      210288 non-null  float32\n",
      " 4   WSpdMph_015m      210288 non-null  float32\n",
      " 5   PkWSpdMph_033m    210217 non-null  float32\n",
      " 6   PkWSpdMph_015m    210091 non-null  float32\n",
      " 7   VSSpdMph_015m     210057 non-null  float32\n",
      " 8   VSSpdMph_033m     210128 non-null  float32\n",
      " 9   SolarRadWm2_015m  210288 non-null  float32\n",
      " 10  BarPresMb_015m    209891 non-null  float32\n",
      " 11  Sigma_033m        210288 non-null  float32\n",
      " 12  Sigma_015m        210288 non-null  float32\n",
      " 13  SigPhi_033m       210219 non-null  float32\n",
      " 14  SigPhi_015m       210149 non-null  float32\n",
      " 15  WDir_033m         210288 non-null  float32\n",
      " 16  WDir_015m         210288 non-null  float32\n",
      " 17  PrecipIn_015m     210288 non-null  float32\n",
      "dtypes: float32(18)\n",
      "memory usage: 16.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the .csv files\n",
    "directory_path = '../data/met_towers_2017-2022_gapfilled-qc' # Replace with your directory path\n",
    "\n",
    "# Initialize an empty dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Skip hidden files and non-CSV files\n",
    "    if file_name.startswith('.') or not file_name.endswith('.csv'):\n",
    "        continue\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    # Read the CSV into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path, index_col=0, na_values=[-999])  # Assuming the first column is the index\n",
    "    \n",
    "    # Convert all non-index columns to float32\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col]).astype('float32')\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with the file name as the key (without .csv)\n",
    "    dataframes[file_name.replace('.csv', '')] = df\n",
    "\n",
    "# Example usage: Access the DataFrame for a specific file\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"DataFrame for {name}:\")\n",
    "    print(df.info())  # Print DataFrame info to confirm the column dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38de77-17a7-478b-b98a-81b7caa47be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwritten: ../data/met_towers_2017-2022_gapfilled-qc/TOWA_2017-2022_gapfilled-qc.csv\n",
      "Overwritten: ../data/met_towers_2017-2022_gapfilled-qc/TOWB_2017-2022_gapfilled-qc.csv\n",
      "Overwritten: ../data/met_towers_2017-2022_gapfilled-qc/TOWD_2017-2022_gapfilled-qc.csv\n",
      "Overwritten: ../data/met_towers_2017-2022_gapfilled-qc/TOWF_2017-2022_gapfilled-qc.csv\n",
      "Overwritten: ../data/met_towers_2017-2022_gapfilled-qc/TOWS_2017-2022_gapfilled-qc.csv\n",
      "Overwritten: ../data/met_towers_2017-2022_gapfilled-qc/TOWY_2017-2022_gapfilled-qc.csv\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the .csv files\n",
    "directory_path = '../data/met_towers_2017-2022_gapfilled-qc'  # Replace with your directory path\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Skip hidden files and non-CSV files\n",
    "    if file_name.startswith('.') or not file_name.endswith('.csv'):\n",
    "        continue\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    # Read the CSV into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path, index_col=0, na_values=[-999])  # Assuming the first column is the index\n",
    "    \n",
    "    # Convert all non-index columns to float32\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
    "    \n",
    "    # Overwrite the original file with the float32 version\n",
    "    df.to_csv(file_path)  # This actually saves the updated DataFrame\n",
    "    print(f\"Overwritten: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92815ea5-e436-44e0-b470-a67e77d6d2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and overwritten: ../data/met_towers_2017-2022_manual-outlier-id/TOWA_2017-2022_manual-outlier-id.csv\n",
      "Processed and overwritten: ../data/met_towers_2017-2022_manual-outlier-id/TOWF_2017-2022_manual-outlier-id.csv\n",
      "Processed and overwritten: ../data/met_towers_2017-2022_manual-outlier-id/TOWB_2017-2022_manual-outlier-id.csv\n",
      "Processed and overwritten: ../data/met_towers_2017-2022_manual-outlier-id/TOWY_2017-2022_manual-outlier-id.csv\n",
      "Processed and overwritten: ../data/met_towers_2017-2022_manual-outlier-id/TOWS_2017-2022_manual-outlier-id.csv\n",
      "Processed and overwritten: ../data/met_towers_2017-2022_manual-outlier-id/TOWD_2017-2022_manual-outlier-id.csv\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the .csv files\n",
    "directory_path = '../data/met_towers_2017-2022_manual-outlier-id'  # Replace with your directory path\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Skip hidden files and non-CSV files\n",
    "    if file_name.startswith('.') or not file_name.endswith('.csv'):\n",
    "        continue\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    # Read the CSV into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path, na_values=[-999])\n",
    "    \n",
    "    # Ensure datetime_start and datetime_end are datetime objects\n",
    "    df['datetime_start'] = pd.to_datetime(df['datetime_start'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    df['datetime_end'] = pd.to_datetime(df['datetime_end'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    \n",
    "    # Ensure tower and column are strings\n",
    "    df['tower'] = df['tower'].astype(str)\n",
    "    df['column'] = df['column'].astype(str)\n",
    "\n",
    "    # print(df.info())\n",
    "    \n",
    "    # Overwrite the original file with the updated DataFrame\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Processed and overwritten: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f7bb9-7aa3-4373-8804-e7bab52432a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store data for the final DataFrame\n",
    "headers_data = []\n",
    "\n",
    "# Specify the parent directory containing the 'met_towers_2017-2022_' directories\n",
    "parent_directory = \"../data/\"\n",
    "\n",
    "# Loop through directories in the parent directory\n",
    "for directory_name in os.listdir(parent_directory):\n",
    "    if directory_name.startswith('met_towers_2017-2022_'):\n",
    "        directory_path = os.path.join(parent_directory, directory_name)\n",
    "        \n",
    "        if os.path.isdir(directory_path) and 'precheck' not in directory_path:\n",
    "            # Loop through CSV files in the current directory\n",
    "            for file_name in os.listdir(directory_path):\n",
    "                if file_name.startswith('.'):  # Skip hidden files\n",
    "                    continue\n",
    "                \n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = os.path.join(directory_path, file_name)\n",
    "                    \n",
    "                    # Try different encodings\n",
    "                    for encoding in ['utf-8-sig', 'utf-8', 'latin1', 'iso-8859-1', 'cp1252']:\n",
    "                        try:\n",
    "                            # Read the file and retrieve its headers and dtypes\n",
    "                            df = pd.read_csv(file_path, nrows=10, encoding=encoding)\n",
    "                            \n",
    "                            for column in df.columns:\n",
    "                                # Handle special cases for 'datetime_start' and 'datetime_end'\n",
    "                                if column in ['datetime_start', 'datetime_end']:\n",
    "                                    shortname = column\n",
    "                                else:\n",
    "                                    # Remove '_Height' or split by '_'\n",
    "                                    shortname = column.split('_')[0]\n",
    "                                \n",
    "                                dtype = df[column].dtype\n",
    "\n",
    "                                # Append the information for this column to the headers_data list\n",
    "                                headers_data.append({\n",
    "                                    \"header_shortname\": shortname,\n",
    "                                    \"header_longname\": None,  # Placeholder for manual entry\n",
    "                                    \"header_description\": None,  # Placeholder for manual entry\n",
    "                                    \"unit\": None,  # Placeholder for manual entry\n",
    "                                    \"dtype\": dtype\n",
    "                                })\n",
    "                            \n",
    "                            # Break out of the encoding loop if successful\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            # If all encodings fail, log the error\n",
    "                            if encoding == ['cp1252'][-1]:\n",
    "                                print(f\"Error reading file {file_path}: {e}\")\n",
    "                            continue\n",
    "\n",
    "# Convert the headers_data list to a DataFrame\n",
    "headers_df = pd.DataFrame(headers_data)\n",
    "\n",
    "# Drop duplicate rows\n",
    "headers_df = headers_df.drop_duplicates()\n",
    "\n",
    "# Save the DataFrame to a CSV file for review and manual entry\n",
    "output_file = \"../data/supplementary/metadata_temp.csv\"\n",
    "headers_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3b365-b7c8-493f-8b7a-79a4e8be28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of names to check for in column names\n",
    "names = [\n",
    "    \"DT\", \"MixHeight\", \"MixRatio\", \"SatMixRatio\", \"SatVaporPres\", \"SonicTemp\", \"StabSigPhi\", \"StabSRDT\", \n",
    "    \"UWind\", \"VaporPres\", \"VWDir\", \"VWind\", \"WElev\", \"SWSpdMph\", \"SWSpdMs\", \"RWSpdMph\", \"RWSpdMs\", \n",
    "    \"RSWSpdMph\", \"RSWSpdMs\", \"SPkWSpdMph\", \"SPkWSpdMs\", \"SWDir\", \"SVWDir\", \"SSigma\", \"DT002m015m\", \n",
    "    \"DT002m035m\", \"DT002m060m\", \"DT015m035m\", \"DT015m060m\", \"SoilTemp\", \"Ri015m035m\", \"Ri015m060m\", \n",
    "    \"Stab\", \"DeltaTemp\", \"LHV\"\n",
    "]\n",
    "\n",
    "# Initialize an empty dictionary to store statistics\n",
    "stats_data = {}\n",
    "\n",
    "# Specify the parent directory containing the 'met_towers_2017-2022_' directories\n",
    "parent_directory = \"/Volumes/55AE_SSD/nsrd_local/data/\"\n",
    "\n",
    "# Loop through directories in the parent directory\n",
    "for directory_name in os.listdir(parent_directory):\n",
    "    if directory_name.startswith('met_towers_2017-2022_') and \"original\" not in directory_name:\n",
    "        directory_path = os.path.join(parent_directory, directory_name)\n",
    "        \n",
    "        if os.path.isdir(directory_path):\n",
    "            # Loop through CSV files in the current directory\n",
    "            for file_name in os.listdir(directory_path):\n",
    "                if file_name.startswith('.'):  # Skip hidden files\n",
    "                    continue\n",
    "                \n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = os.path.join(directory_path, file_name)\n",
    "                    \n",
    "                    # Try different encodings\n",
    "                    for encoding in ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']:\n",
    "                        try:\n",
    "                            # Read the file and retrieve its data\n",
    "                            df = pd.read_csv(file_path, encoding=encoding)\n",
    "                            \n",
    "                            # Loop through each column in the DataFrame\n",
    "                            for column in df.columns:\n",
    "                                # Check if the column name contains any string from the names list\n",
    "                                if any(name in column for name in names):\n",
    "                                    # Extract non-NaN values from the column\n",
    "                                    non_nan_values = df[column].dropna()\n",
    "\n",
    "                                    # If there are any non-NaN values, calculate statistics\n",
    "                                    if not non_nan_values.empty:\n",
    "                                        col_min = non_nan_values.min()\n",
    "                                        col_mean = non_nan_values.mean()\n",
    "                                        col_max = non_nan_values.max()\n",
    "\n",
    "                                        # Store the statistics in the dictionary\n",
    "                                        if column not in stats_data:\n",
    "                                            stats_data[column] = []\n",
    "                                        stats_data[column].append({\n",
    "                                            \"file\": file_name,\n",
    "                                            \"min\": col_min,\n",
    "                                            \"mean\": col_mean,\n",
    "                                            \"max\": col_max\n",
    "                                        })\n",
    "                            \n",
    "                            # Break out of the encoding loop if successful\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            # If all encodings fail, log the error\n",
    "                            if encoding == ['cp1252'][-1]:\n",
    "                                print(f\"Error reading file {file_path}: {e}\")\n",
    "                            continue\n",
    "\n",
    "# Convert the stats dictionary into a DataFrame for export\n",
    "stats_flattened = []\n",
    "for column, stats in stats_data.items():\n",
    "    for stat in stats:\n",
    "        stats_flattened.append({\"column\": column, **stat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b5ecf-50fb-4714-902c-dce767bd41f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
