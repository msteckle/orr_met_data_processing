{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f85f16-8afc-40fd-a2e2-431a17781889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b53cf0-2735-4e6b-8495-348b090fdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit parameters\n",
    "YEARS = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "MN_DATA_DIR = '../data/source_data_015m'\n",
    "HR_DATA_DIR = '../data/source_data_060m'\n",
    "IMG_DIR = '../graphics'\n",
    "MET_RANGES = '../data/supplementary/met_inst_ranges.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71023aa5-0103-40b7-8022-43972bf35e26",
   "metadata": {},
   "source": [
    "---\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47146104-8daf-49f1-87ae-7cf4c85ffc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create list of tower names\n",
    "def get_unique_towers(data_files):\n",
    "    tower_names = []\n",
    "    for file in data_files:\n",
    "        file_name = file.split('/')[-1]\n",
    "        tower_name = file_name.split('_')[0]\n",
    "        tower_names.append(tower_name)\n",
    "    unique_tower_names = sorted(list(set(tower_names)))\n",
    "    return unique_tower_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f2c8a7-f733-4626-804c-69d6e0ac524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make sure dfs have columns for all timestamps (jan17 to dec22)\n",
    "def standardize_dateranges(df_list, frequency, sdate, edate):\n",
    "    new_dfs = []\n",
    "    for df in df_list:\n",
    "        df['ts'] = df.index.to_list()\n",
    "        df = df.groupby('ts').first()\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df['date_end'] = df.index.to_list()\n",
    "        df1 = df.reindex(pd.date_range(sdate, edate, freq=frequency))\n",
    "        df1.drop(columns=['date_end'], inplace=True)\n",
    "        new_dfs.append(df1)\n",
    "    return new_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944ac4b8-5a1c-4f1f-bdff-ef6e7b83f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that masks values (set as NaN) that are outside of min/max limits\n",
    "# oor = out of range\n",
    "def mask_oor(row):\n",
    "    min = row.iloc[-2] # min col\n",
    "    max = row.iloc[-1] # max col\n",
    "    col = row.iloc[0] # colname\n",
    "    row = row.iloc[1:-2] # drop extra non-numeric cols\n",
    "    if not math.isnan(min):\n",
    "        if 'RelHum' in col:\n",
    "            new_row = row.mask((row.gt(max) | row.lt(min)), 100)\n",
    "        else:\n",
    "            new_row = row.mask((row.gt(max) | row.lt(min)), np.nan)\n",
    "    else:\n",
    "        new_row = row\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674bc35e-0efa-43df-88e4-e7f2ae8b804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to mask (set as NaN) values that have too high of an hourly rate change\n",
    "# roc = rate of change\n",
    "def mask_rapid_roc(tdf):\n",
    "\n",
    "    # sub-function to find large value differences\n",
    "    def mask_and_resample(in_df, colname, name, limit):\n",
    "        roc = f'{name.lower()}_roc'\n",
    "        df = in_df.copy()\n",
    "        df = df.iloc[::4, :] # select every fourth row (every hour)\n",
    "        df[roc] = df[colname].diff() # get diff between hour timestamps\n",
    "        df[roc] = abs(df[roc]) # get abs value of differences\n",
    "        sdf = standardize_dateranges([df], '15Min', '2017-01-01 00:00:00', '2022-12-31 23:45:00') # bring back to 15-min\n",
    "        sdf = sdf[0].ffill(limit=3) # forward fill numbers for an hour\n",
    "        in_df[colname].mask(sdf[roc] > limit) # mask any numbers greater than diff limit\n",
    "        out_df = pd.DataFrame(in_df[colname])\n",
    "        return out_df # return masked column as dataframe\n",
    "    \n",
    "    for colname in tdf.columns.to_list():\n",
    "        name = colname.split('_')[0]\n",
    "        if name == 'TempC':\n",
    "            maskdf = mask_and_resample(tdf, colname, name, 5)\n",
    "            tdf[colname] = maskdf[colname]\n",
    "        elif name == 'TempF':\n",
    "            maskdf = mask_and_resample(tdf, colname, name, 10)\n",
    "            tdf[colname] = maskdf[colname]\n",
    "        elif name == 'RelHum':\n",
    "            maskdf = mask_and_resample(tdf, colname, name, 25)\n",
    "            tdf[colname] = maskdf[colname]\n",
    "        else:\n",
    "            tdf[colname] = tdf[colname]\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9789d4ef-2c40-4a97-aeb3-8739c0d3f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulas to calculate missing columns\n",
    "# temperature conversions\n",
    "def tempf_to_tempc(tempF):\n",
    "    tempC = (tempF - 32)*(5/9)\n",
    "    return tempC\n",
    "def tempk_to_tempc(tempK):\n",
    "    tempC = tempK - 273.15\n",
    "    return tempC\n",
    "def tempc_to_tempk(tempC):\n",
    "    tempK = tempC + 273.15\n",
    "    return tempK\n",
    "\n",
    "# precipitation conversions\n",
    "def mm_to_in(precipMm):\n",
    "    precipIn = precipMm/25.4\n",
    "    return precipIn\n",
    "\n",
    "# speed conversions\n",
    "def ms_to_mph(spdMs):\n",
    "    spdMph = spdMs * 2.237\n",
    "    return spdMph\n",
    "    \n",
    "# pressure conversions\n",
    "def mb_to_in(barPresMb):\n",
    "    barPresIn = barPresMb * 0.0295301\n",
    "    return barPresIn\n",
    "def in_to_mb(barPresIn):\n",
    "    barPresMb = barPresIn * 33.8637526\n",
    "    return barPresMb\n",
    "\n",
    "# solar radiation conversions\n",
    "def lang_to_wm2(solarRadLang):\n",
    "    solarRadWm2 = solarRadLang * 697.9\n",
    "    return solarRadWm2\n",
    "\n",
    "# calculate absolute humidity from\n",
    "# TempK, BarPresIn, RelHum\n",
    "def satVaporPres(tempK):\n",
    "    satVaporPres = 6.108 ** ((17.3 * (tempK - 273.15)) / (237.3 + (tempK - 273.15)))\n",
    "    return satVaporPres\n",
    "def satMixRatio(satVaporPres, barPresIn):\n",
    "    satMixRatio = (0.622 * satVaporPres) / (barPresIn * 33.86)\n",
    "    return satMixRatio\n",
    "def mixRatio(relHum, satMixRatio):\n",
    "    mixRatio = (relHum * satMixRatio) / 100\n",
    "    return mixRatio\n",
    "def vaporPres(barPresIn, mixRatio):\n",
    "    vaporPres = ((barPresIn * 33.86) * mixRatio) / (0.622 + mixRatio)\n",
    "    return vaporPres\n",
    "def absHum(vaporPres, tempK):\n",
    "    absHum = ((vaporPres*100) / (tempK*461.5)) * 1000\n",
    "    return absHum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0fb1b1d-3d17-4f80-bfda-6248be620060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate missing columns\n",
    "def calc_missing_cols(tower_dfs):\n",
    "    \n",
    "    i = 0\n",
    "    tower_dfs_out = []\n",
    "    for df in tower_dfs:\n",
    "    \n",
    "        print(f'Tower #{i}')\n",
    "        df = df.astype(np.float32)\n",
    "        colnames = df.columns\n",
    "        heights = set([colname.split('_')[1] for colname in colnames])\n",
    "        \n",
    "        for height in heights:\n",
    "    \n",
    "            # temperature vars\n",
    "            TempC_present = f'TempC_{height}' in colnames\n",
    "            if not TempC_present:\n",
    "                \n",
    "                TempF_present = f'TempF_{height}' in colnames\n",
    "                TempK_present = f'TempK_{height}' in colnames\n",
    "                if TempF_present:\n",
    "                    tc = f'TempC_{height}'\n",
    "                    refcol = f'TempF_{height}'\n",
    "                    df[tc] = df[refcol].apply(tempf_to_tempc)\n",
    "                    \n",
    "                elif TempK_present:\n",
    "                    tc = f'TempC_{height}'\n",
    "                    refcol = f'TempK_{height}'\n",
    "                    df[tc] = df[refcol].apply(tempk_to_tempc)\n",
    "        \n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "            TempK_present = f'TempK_{height}' in colnames\n",
    "            if TempC_present and not TempK_present:\n",
    "                tk = f'TempK_{height}'\n",
    "                refcol = f'TempC_{height}'\n",
    "                df[tk] = df[refcol].apply(tempc_to_tempk)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "            # precipitation vars\n",
    "            PrecipIn_present = f'PrecipIn_{height}' in colnames\n",
    "            PrecipMm_present = f'PrecipMm_{height}' in colnames\n",
    "            if PrecipMm_present and not PrecipIn_present:\n",
    "                pi = f'PrecipIn_{height}'\n",
    "                refcol = f'PrecipMm_{height}'\n",
    "                df[pi] = df[refcol].apply(mm_to_in)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "            # pressure vars\n",
    "            BarPresMb_present = f'BarPresMb_{height}' in colnames\n",
    "            BarPresIn_present = f'BarPresIn_{height}' in colnames\n",
    "            if BarPresMb_present and not BarPresIn_present:\n",
    "                bpi = f'BarPresIn_{height}'\n",
    "                refcol = f'BarPresMb_{height}'\n",
    "                df[bpi] = df[refcol].apply(mb_to_in)\n",
    "            elif BarPresIn_present and not BarPresMb_present:\n",
    "                bpm = f'BarPresMb_{height}'\n",
    "                refcol = f'BarPresIn_{height}'\n",
    "                df[bpm] = df[refcol].apply(in_to_mb)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "            # speed vars\n",
    "            WSpdMs_present = f'WSpdMs_{height}' in colnames\n",
    "            WSpd_present = f'WSpdMph_{height}' in colnames\n",
    "            if WSpdMs_present and not WSpd_present:\n",
    "                ws = f'WSpdMph_{height}'\n",
    "                refcol = f'WSpdMs_{height}'\n",
    "                df[ws] = df[refcol].apply(ms_to_mph)\n",
    "            VSSpdMs_present = f'VSSpdMs_{height}' in colnames\n",
    "            VSSpd_present = f'VSSpdMph_{height}' in colnames\n",
    "            if VSSpdMs_present and not VSSpd_present:\n",
    "                vs = f'VSSpdMph_{height}'\n",
    "                refcol = f'VSSpdMs_{height}'\n",
    "                df[vs] = df[refcol].apply(ms_to_mph)\n",
    "            PkWSpdMs_present = f'PkWSpdMs_{height}' in colnames\n",
    "            PkWSpd_present = f'PkWSpdMph_{height}' in colnames\n",
    "            if PkWSpdMs_present and not PkWSpd_present:\n",
    "                vs = f'PkWSpdMph_{height}'\n",
    "                refcol = f'PkWSpdMs_{height}'\n",
    "                df[vs] = df[refcol].apply(ms_to_mph)\n",
    "            # rename speed cols to include unit\n",
    "            WSpd_present = f'WSpd_{height}' in colnames\n",
    "            if WSpd_present:\n",
    "                df = df.rename(columns={f'WSpd_{height}':f'WSpdMph_{height}'})\n",
    "            VSSpd_present = f'VSSpd_{height}' in colnames\n",
    "            if VSSpd_present:\n",
    "                df = df.rename(columns={f'VSSpd_{height}':f'VSSpdMph_{height}'})\n",
    "            PkWSpd_present = f'PkWSpd_{height}' in colnames\n",
    "            if PkWSpd_present:\n",
    "                df = df.rename(columns={f'PkWSpd_{height}':f'PkWSpdMph_{height}'})\n",
    "    \n",
    "            # solar radiation vars\n",
    "            SolarRadLang_present = f'SolarRadLang_{height}' in colnames\n",
    "            SolarRadWm2_present = f'SolarRadWm2_{height}' in colnames\n",
    "            if SolarRadLang_present and not SolarRadWm2_present:\n",
    "                srw = f'SolarRadWm2_{height}'\n",
    "                refcol = f'SolarRadLang_{height}'\n",
    "                df[srw] = df[refcol].apply(lang_to_wm2)\n",
    "    \n",
    "            # absolute humidity\n",
    "            AbsHum_present = f'AbsHum_{height}' in colnames\n",
    "            if not AbsHum_present:\n",
    "                TempK_present = f'TempK_{height}' in colnames\n",
    "                BarPresIn_present = f'BarPresIn_{height}' in colnames\n",
    "                RelHum_present = f'RelHum_{height}' in colnames\n",
    "                if TempK_present and BarPresIn_present and RelHum_present:\n",
    "                    \n",
    "                    # in vars\n",
    "                    rh = f'RelHum_{height}'\n",
    "                    bpi = f'BarPresIn_{height}'\n",
    "                    tk = f'TempK_{height}'\n",
    "                    \n",
    "                    # saturated vapor pressure\n",
    "                    svp = f'SatVaporPres_{height}'\n",
    "                    df[svp] = df[tk].apply(satVaporPres)\n",
    "                    \n",
    "                    # saturated mixing ratio\n",
    "                    smr = f'SatMixRatio_{height}'\n",
    "                    df[smr] = df.apply(lambda x: satMixRatio(x[svp], x[bpi]), axis=1)\n",
    "                                       \n",
    "                    # mixing ratio\n",
    "                    mr = f'MixRatio_{height}'\n",
    "                    df[mr] = df.apply(lambda x: mixRatio(x[rh], x[smr]), axis=1)\n",
    "                                      \n",
    "                    # vapor pressure\n",
    "                    vp = f'VaporPres_{height}'\n",
    "                    df[vp] = df.apply(lambda x: vaporPres(x[bpi], x[mr]), axis=1)\n",
    "                                      \n",
    "                    # absolute humidity\n",
    "                    ah = f'AbsHum_{height}'\n",
    "                    df[ah] = df.apply(lambda x: absHum(x[vp], x[tk]), axis=1)\n",
    "    \n",
    "        tower_dfs_out.append(df)\n",
    "        i += 1\n",
    "        \n",
    "    return tower_dfs_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb90ac-576a-4e36-9c94-e69b9e1e1590",
   "metadata": {},
   "source": [
    "---\n",
    "# Variable limits\n",
    "### Load table with min/max limits of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4303e7d4-338a-4a44-a1ac-0a6e738afdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables with limits\n",
    "limits = pd.read_csv(MET_RANGES)\n",
    "limits.set_index('Sensor', drop=True, inplace=True)\n",
    "roc = limits[limits['Error Type'] == 'Hourly Rate of Change Error'] # roc = rate of change\n",
    "oor = limits[limits['Error Type'] == 'Out of Range Values'] # oor = out of range\n",
    "oor = oor[['Min', 'Max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0eb6e7-f77b-4a9c-8a49-4afbd4eb4789",
   "metadata": {},
   "source": [
    "---\n",
    "# 60-minute interval meteorology data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d373d0-3707-4557-ad55-cca0e5d75c1a",
   "metadata": {},
   "source": [
    "### 1. Clean annual sheets before merging into one multi-annual sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d100e264-4705-426e-a04e-2e19b7b886fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one dataframe per tower for all years\n",
    "# towers_of_interest = ['TOWA', 'TOWB', 'TOWD', 'TOWF', 'TOWS', 'TOWY']\n",
    "# tower_dfs_60m = []\n",
    "# for tower in towers_of_interest:\n",
    "#     print(tower)\n",
    "#     year_dfs = []\n",
    "#     for year in YEARS:\n",
    "#         files = sorted(glob.glob(f'{HR_DATA_DIR}/{tower}/*{year}.csv'))\n",
    "#         for file in files:\n",
    "#             year_df = pd.read_csv(file, header=0, dtype='Float32', na_values=['-999.0', '#DIV/0!', -999])\n",
    "#             year_df = year_df.rename(columns=lambda x: x.strip())\n",
    "#             year_df.columns = year_df.columns.astype(str)\n",
    "#             year_dfs.append(year_df)\n",
    "#     df = pd.concat(year_dfs, axis=0)\n",
    "#     tower_dfs_60m.append(df)\n",
    "\n",
    "# create timestamp for 60-minute data\n",
    "# tower_dfs_60m_2 = []\n",
    "# for df, tower in zip(tower_dfs_60m, towers_of_interest):\n",
    "\n",
    "#     print(tower)\n",
    "    \n",
    "#     # rename date columns\n",
    "#     df = df.rename(columns={'Unnamed: 0':'year', 'Unnamed: 1':'month', 'Unnamed: 2':'day', 'Unnamed: 3':'hour'})\n",
    "#     df[['year', 'month', 'day', 'hour']] = (df[['year', 'month', 'day', 'hour']].astype(int)).astype(str)\n",
    "    \n",
    "#     # clean issues\n",
    "#     df['hour'] = (df.hour.astype(int) - 1).astype(str)\n",
    "#     df['year'] = np.where(df.year.str.contains('7'), '2017', df.year)\n",
    "\n",
    "#     try:\n",
    "#         # create timestamp\n",
    "#         df['timestamp'] = df.year + '-' + df.month + '-' + df.day + ' ' + df.hour + ':00:00'\n",
    "#         df.index = pd.to_datetime(df['timestamp'])\n",
    "#         df.drop(columns=['timestamp', 'year', 'month', 'day', 'hour'], inplace=True)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "#     df.index.name = None\n",
    "#     tower_dfs_60m_2.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d8d6c-662e-4169-8e32-6b8357032f80",
   "metadata": {},
   "source": [
    "### 2. Load multi-annual 60-minute tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9878f93d-08a7-42ab-ab7f-3585a039006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOWA\n",
      "TOWB\n",
      "TOWD\n",
      "TOWF\n",
      "TOWS\n",
      "TOWY\n"
     ]
    }
   ],
   "source": [
    "towers_of_interest = sorted(['TOWA', 'TOWB', 'TOWD', 'TOWF', 'TOWS', 'TOWY'])\n",
    "tower_dfs_60m = []\n",
    "for tower in towers_of_interest:\n",
    "    print(tower)\n",
    "    path = f'{HR_DATA_DIR}/{tower}_2017-2022.csv'\n",
    "    df = pd.read_csv(path, index_col=0, header=0, na_values=['-999.0', '#DIV/0!', -999])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    tower_dfs_60m.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a12b45-3ccb-4f04-9a22-e7767cf73d86",
   "metadata": {},
   "source": [
    "### 3. Mask values outside of normal range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbfd702f-f0d1-41e3-a98b-576c8dc613b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TempF</th>\n",
       "      <td>-30.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempC</th>\n",
       "      <td>-30.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelHum</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPtF</th>\n",
       "      <td>-36.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPtC</th>\n",
       "      <td>-35.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbsHum</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarPresIn</th>\n",
       "      <td>28.500000</td>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarPresMb</th>\n",
       "      <td>965.116949</td>\n",
       "      <td>1032.844454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SolarRadWm2</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SolarRadLang</th>\n",
       "      <td>-0.429925</td>\n",
       "      <td>107.481250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDir</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSpdMph</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSpdMs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PkWSpdMph</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PkWSpdMs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.408136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSSpdMph</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSSpdMs</th>\n",
       "      <td>-1.341082</td>\n",
       "      <td>1.341082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sigma</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SigPhi</th>\n",
       "      <td>-61.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecipIn</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecipMm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Min          Max\n",
       "Sensor                               \n",
       "TempF         -30.000000   110.000000\n",
       "TempC         -30.000000    45.000000\n",
       "RelHum          0.000000   100.000000\n",
       "DewPtF        -36.000000    82.000000\n",
       "DewPtC        -35.000000    28.000000\n",
       "AbsHum          0.100000    28.000000\n",
       "BarPresIn      28.500000    30.500000\n",
       "BarPresMb     965.116949  1032.844454\n",
       "SolarRadWm2    -5.000000  1250.000000\n",
       "SolarRadLang   -0.429925   107.481250\n",
       "WDir            0.000000   360.000000\n",
       "WSpdMph         0.000000    50.000000\n",
       "WSpdMs          0.000000    22.500000\n",
       "PkWSpdMph       0.000000   115.000000\n",
       "PkWSpdMs        0.000000    51.408136\n",
       "VSSpdMph       -3.000000     3.000000\n",
       "VSSpdMs        -1.341082     1.341082\n",
       "Sigma           0.000000   180.000000\n",
       "SigPhi        -61.000000    61.000000\n",
       "PrecipIn        0.000000          inf\n",
       "PrecipMm        0.000000          inf"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc53444c-092c-4362-8824-7f0237bc3a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_name</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <th>2017-01-01 05:00:00</th>\n",
       "      <th>2017-01-01 06:00:00</th>\n",
       "      <th>2017-01-01 07:00:00</th>\n",
       "      <th>2017-01-01 08:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-12-31 16:00:00</th>\n",
       "      <th>2022-12-31 17:00:00</th>\n",
       "      <th>2022-12-31 18:00:00</th>\n",
       "      <th>2022-12-31 19:00:00</th>\n",
       "      <th>2022-12-31 20:00:00</th>\n",
       "      <th>2022-12-31 21:00:00</th>\n",
       "      <th>2022-12-31 22:00:00</th>\n",
       "      <th>2022-12-31 23:00:00</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AbsHum</th>\n",
       "      <td>AbsHum_015m</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarPresIn</th>\n",
       "      <td>BarPresIn_015m</td>\n",
       "      <td>29.09</td>\n",
       "      <td>29.09</td>\n",
       "      <td>29.1</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.14</td>\n",
       "      <td>29.15</td>\n",
       "      <td>29.17</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.02</td>\n",
       "      <td>29.03</td>\n",
       "      <td>29.04</td>\n",
       "      <td>29.06</td>\n",
       "      <td>29.07</td>\n",
       "      <td>29.08</td>\n",
       "      <td>29.09</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarPresMb</th>\n",
       "      <td>BarPresMb_015m</td>\n",
       "      <td>985.2</td>\n",
       "      <td>985.2</td>\n",
       "      <td>985.4</td>\n",
       "      <td>985.9</td>\n",
       "      <td>986.0</td>\n",
       "      <td>986.2</td>\n",
       "      <td>986.7</td>\n",
       "      <td>987.1</td>\n",
       "      <td>987.7</td>\n",
       "      <td>...</td>\n",
       "      <td>982.3</td>\n",
       "      <td>982.7</td>\n",
       "      <td>983.3</td>\n",
       "      <td>983.7</td>\n",
       "      <td>984.1</td>\n",
       "      <td>984.5</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.2</td>\n",
       "      <td>965.116949</td>\n",
       "      <td>1032.844454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPtC</th>\n",
       "      <td>DewPtC_015m</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>13.303111</td>\n",
       "      <td>13.013722</td>\n",
       "      <td>11.336805</td>\n",
       "      <td>12.226973</td>\n",
       "      <td>11.413139</td>\n",
       "      <td>10.426528</td>\n",
       "      <td>9.918944</td>\n",
       "      <td>9.841639</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPtF</th>\n",
       "      <td>DewPtF_015m</td>\n",
       "      <td>37.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>39.1</td>\n",
       "      <td>39.8</td>\n",
       "      <td>39.8</td>\n",
       "      <td>40.1</td>\n",
       "      <td>40.3</td>\n",
       "      <td>40.5</td>\n",
       "      <td>...</td>\n",
       "      <td>55.9456</td>\n",
       "      <td>55.4247</td>\n",
       "      <td>52.40625</td>\n",
       "      <td>54.00855</td>\n",
       "      <td>52.54365</td>\n",
       "      <td>50.76775</td>\n",
       "      <td>49.8541</td>\n",
       "      <td>49.71495</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                orig_name 2017-01-01 00:00:00 2017-01-01 01:00:00  \\\n",
       "AbsHum        AbsHum_015m                 6.0                 6.1   \n",
       "BarPresIn  BarPresIn_015m               29.09               29.09   \n",
       "BarPresMb  BarPresMb_015m               985.2               985.2   \n",
       "DewPtC        DewPtC_015m                 3.1                 3.4   \n",
       "DewPtF        DewPtF_015m                37.7                38.0   \n",
       "\n",
       "          2017-01-01 02:00:00 2017-01-01 03:00:00 2017-01-01 04:00:00  \\\n",
       "AbsHum                    6.2                 6.3                 6.5   \n",
       "BarPresIn                29.1               29.12               29.12   \n",
       "BarPresMb               985.4               985.9               986.0   \n",
       "DewPtC                    3.6                 4.0                 4.3   \n",
       "DewPtF                   38.5                39.1                39.8   \n",
       "\n",
       "          2017-01-01 05:00:00 2017-01-01 06:00:00 2017-01-01 07:00:00  \\\n",
       "AbsHum                    6.5                 6.6                 6.6   \n",
       "BarPresIn               29.12               29.14               29.15   \n",
       "BarPresMb               986.2               986.7               987.1   \n",
       "DewPtC                    4.3                 4.5                 4.6   \n",
       "DewPtF                   39.8                40.1                40.3   \n",
       "\n",
       "          2017-01-01 08:00:00  ... 2022-12-31 16:00:00 2022-12-31 17:00:00  \\\n",
       "AbsHum                    6.7  ...                11.6                11.4   \n",
       "BarPresIn               29.17  ...                29.0               29.02   \n",
       "BarPresMb               987.7  ...               982.3               982.7   \n",
       "DewPtC                    4.7  ...           13.303111           13.013722   \n",
       "DewPtF                   40.5  ...             55.9456             55.4247   \n",
       "\n",
       "          2022-12-31 18:00:00 2022-12-31 19:00:00 2022-12-31 20:00:00  \\\n",
       "AbsHum                   10.4                10.7                10.2   \n",
       "BarPresIn               29.03               29.04               29.06   \n",
       "BarPresMb               983.3               983.7               984.1   \n",
       "DewPtC              11.336805           12.226973           11.413139   \n",
       "DewPtF               52.40625            54.00855            52.54365   \n",
       "\n",
       "          2022-12-31 21:00:00 2022-12-31 22:00:00 2022-12-31 23:00:00  \\\n",
       "AbsHum                    9.6                 9.3                 9.2   \n",
       "BarPresIn               29.07               29.08               29.09   \n",
       "BarPresMb               984.5               985.0               985.2   \n",
       "DewPtC              10.426528            9.918944            9.841639   \n",
       "DewPtF               50.76775             49.8541            49.71495   \n",
       "\n",
       "                  Min          Max  \n",
       "AbsHum       0.100000    28.000000  \n",
       "BarPresIn   28.500000    30.500000  \n",
       "BarPresMb  965.116949  1032.844454  \n",
       "DewPtC     -35.000000    28.000000  \n",
       "DewPtF     -36.000000    82.000000  \n",
       "\n",
       "[5 rows x 52587 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare dataframe by adding associated min/max to variables (where applicable)\n",
    "tower_dfs_60m_2 = []\n",
    "for df in tower_dfs_60m:\n",
    "    temp = df.T.reset_index().T.reset_index() # pushes header down into row\n",
    "    temp = temp.set_index('index', drop=True) # puts timeseries index back in place\n",
    "    colnames = temp.loc['index'].to_list() # get variable names\n",
    "    temp.columns = [x.split('_')[0] for x in colnames] # get first word from variable name\n",
    "    out_df = temp.T # transpose variables from columns to indices\n",
    "    out_df = out_df.rename(columns=dict(index='orig_name'))\n",
    "    out_df = out_df.merge(oor, how='left', left_index=True, right_index=True) # join OOR table to get limits\n",
    "    tower_dfs_60m_2.append(out_df)\n",
    "tower_dfs_60m_2[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab231f8-30f0-4c4d-a84d-6c70cd09f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask values outside of acceptable limits\n",
    "tower_dfs_60m_3 = []\n",
    "for df in tower_dfs_60m_2:\n",
    "    out_df = df.apply(lambda row: mask_oor(row), axis=1)\n",
    "    out_df.index = df['orig_name']\n",
    "    out_df = out_df.T\n",
    "    out_df.index = pd.to_datetime(out_df.index)\n",
    "    tower_dfs_60m_3.append(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a53976aa-85df-43ef-aefc-0cea9302e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029607157026814983\n",
      "2.6230412292712613\n",
      "7.101416201985726\n",
      "9.918329125734044\n",
      "1.9665504889147063\n",
      "2.310538727009216\n"
     ]
    }
   ],
   "source": [
    "for df, df3 in zip(tower_dfs_60m, tower_dfs_60m_3):\n",
    "    comparison = df == df3\n",
    "    num_differences = (~comparison).sum().sum()  # ~ negates the boolean (True -> False, False -> True)\n",
    "    total_elements = df.size\n",
    "    percent_changed = (num_differences / total_elements) * 100\n",
    "    print(percent_changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c5696-4795-4161-a478-582dc2acea97",
   "metadata": {},
   "source": [
    "### 4. Convert 60-minute data intervals into 15-minute intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44fc6141-e84d-4621-87d1-fc6e76ba7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize date range\n",
    "warnings.filterwarnings('ignore')\n",
    "tower_dfs_60m_4 = standardize_dateranges(tower_dfs_60m_3, '15Min', '2017-01-01 00:00:00', '2022-12-31 23:45:00')\n",
    "\n",
    "# make sure dfs are clean\n",
    "tower_dfs_60m_5 = []\n",
    "for df in tower_dfs_60m_4:\n",
    "    df = df.astype('Float32')\n",
    "    df.columns.name = None\n",
    "    tower_dfs_60m_5.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6763a89-69bc-4781-b99b-e2bc24b08a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>BarPresIn_015m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>DewPtC_015m</th>\n",
       "      <th>DewPtF_015m</th>\n",
       "      <th>DT_030m</th>\n",
       "      <th>MixHeight_015m</th>\n",
       "      <th>MixRatio_015m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>...</th>\n",
       "      <th>VWind_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>WElev_015m</th>\n",
       "      <th>WElev_030m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "      <th>WSpdMs_015m</th>\n",
       "      <th>WSpdMs_030m</th>\n",
       "      <th>WSpdRatio030m015m_015m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>29.09</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>3.1</td>\n",
       "      <td>37.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>6.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171487</td>\n",
       "      <td>261.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.11795</td>\n",
       "      <td>1.967592</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:15:00</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:45:00</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>6.1</td>\n",
       "      <td>29.09</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>3.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057744</td>\n",
       "      <td>266.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.89436</td>\n",
       "      <td>1.654566</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AbsHum_015m  BarPresIn_015m  BarPresMb_015m  DewPtC_015m  \\\n",
       "2017-01-01 00:00:00          6.0           29.09      985.200012          3.1   \n",
       "2017-01-01 00:15:00         <NA>            <NA>            <NA>         <NA>   \n",
       "2017-01-01 00:30:00         <NA>            <NA>            <NA>         <NA>   \n",
       "2017-01-01 00:45:00         <NA>            <NA>            <NA>         <NA>   \n",
       "2017-01-01 01:00:00          6.1           29.09      985.200012          3.4   \n",
       "\n",
       "                     DewPtF_015m  DT_030m  MixHeight_015m  MixRatio_015m  \\\n",
       "2017-01-01 00:00:00    37.700001      0.0           800.0       0.004881   \n",
       "2017-01-01 00:15:00         <NA>     <NA>            <NA>           <NA>   \n",
       "2017-01-01 00:30:00         <NA>     <NA>            <NA>           <NA>   \n",
       "2017-01-01 00:45:00         <NA>     <NA>            <NA>           <NA>   \n",
       "2017-01-01 01:00:00         38.0      0.0           620.0       0.004947   \n",
       "\n",
       "                     PkWSpdMph_015m  PkWSpdMph_030m  ...  VWind_030m  \\\n",
       "2017-01-01 00:00:00             6.7            10.2  ...   -0.171487   \n",
       "2017-01-01 00:15:00            <NA>            <NA>  ...        <NA>   \n",
       "2017-01-01 00:30:00            <NA>            <NA>  ...        <NA>   \n",
       "2017-01-01 00:45:00            <NA>            <NA>  ...        <NA>   \n",
       "2017-01-01 01:00:00             5.3             6.3  ...   -0.057744   \n",
       "\n",
       "                     WDir_015m  WDir_030m  WElev_015m  WElev_030m  \\\n",
       "2017-01-01 00:00:00      261.0      265.0         0.2         0.5   \n",
       "2017-01-01 00:15:00       <NA>       <NA>        <NA>        <NA>   \n",
       "2017-01-01 00:30:00       <NA>       <NA>        <NA>        <NA>   \n",
       "2017-01-01 00:45:00       <NA>       <NA>        <NA>        <NA>   \n",
       "2017-01-01 01:00:00      266.0      268.0        -2.0        -0.3   \n",
       "\n",
       "                     WSpdMph_015m  WSpdMph_030m  WSpdMs_015m  WSpdMs_030m  \\\n",
       "2017-01-01 00:00:00           2.5           4.4      1.11795     1.967592   \n",
       "2017-01-01 00:15:00          <NA>          <NA>         <NA>         <NA>   \n",
       "2017-01-01 00:30:00          <NA>          <NA>         <NA>         <NA>   \n",
       "2017-01-01 00:45:00          <NA>          <NA>         <NA>         <NA>   \n",
       "2017-01-01 01:00:00           2.0           3.7      0.89436     1.654566   \n",
       "\n",
       "                     WSpdRatio030m015m_015m  \n",
       "2017-01-01 00:00:00                    1.76  \n",
       "2017-01-01 00:15:00                    <NA>  \n",
       "2017-01-01 00:30:00                    <NA>  \n",
       "2017-01-01 00:45:00                    <NA>  \n",
       "2017-01-01 01:00:00                    1.85  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_60m_5[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b22b35-5078-4e7e-94f5-00b1e5747a0a",
   "metadata": {},
   "source": [
    "### 5. Interpolate new 15-minute intervals (of 60-minute data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb449491-9dc6-42e8-b13f-989615e248d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>BarPresIn_015m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>DewPtC_015m</th>\n",
       "      <th>DewPtF_015m</th>\n",
       "      <th>DT_030m</th>\n",
       "      <th>MixHeight_015m</th>\n",
       "      <th>MixRatio_015m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>...</th>\n",
       "      <th>VWind_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>WElev_015m</th>\n",
       "      <th>WElev_030m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "      <th>WSpdMs_015m</th>\n",
       "      <th>WSpdMs_030m</th>\n",
       "      <th>WSpdRatio030m015m_015m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>29.09</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>3.1</td>\n",
       "      <td>37.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>6.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171487</td>\n",
       "      <td>261.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.11795</td>\n",
       "      <td>1.967592</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:15:00</th>\n",
       "      <td>6.02116</td>\n",
       "      <td>29.08968</td>\n",
       "      <td>985.203247</td>\n",
       "      <td>3.208987</td>\n",
       "      <td>37.743874</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>685.605896</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>6.473885</td>\n",
       "      <td>8.82041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149512</td>\n",
       "      <td>259.699219</td>\n",
       "      <td>263.712219</td>\n",
       "      <td>-0.596983</td>\n",
       "      <td>0.469096</td>\n",
       "      <td>2.325163</td>\n",
       "      <td>4.172241</td>\n",
       "      <td>1.039766</td>\n",
       "      <td>1.865743</td>\n",
       "      <td>1.80243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>6.045611</td>\n",
       "      <td>29.089455</td>\n",
       "      <td>985.200134</td>\n",
       "      <td>3.290628</td>\n",
       "      <td>37.810856</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>627.120972</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>6.141582</td>\n",
       "      <td>7.728683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120539</td>\n",
       "      <td>260.691956</td>\n",
       "      <td>264.206818</td>\n",
       "      <td>-1.214409</td>\n",
       "      <td>0.287896</td>\n",
       "      <td>2.187686</td>\n",
       "      <td>3.984347</td>\n",
       "      <td>0.97829</td>\n",
       "      <td>1.78172</td>\n",
       "      <td>1.829682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:45:00</th>\n",
       "      <td>6.072257</td>\n",
       "      <td>29.089504</td>\n",
       "      <td>985.19696</td>\n",
       "      <td>3.351955</td>\n",
       "      <td>37.897408</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>610.075623</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>5.738489</td>\n",
       "      <td>6.897614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088604</td>\n",
       "      <td>263.088715</td>\n",
       "      <td>265.848022</td>\n",
       "      <td>-1.674631</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>2.081367</td>\n",
       "      <td>3.829279</td>\n",
       "      <td>0.930745</td>\n",
       "      <td>1.712377</td>\n",
       "      <td>1.844593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>6.1</td>\n",
       "      <td>29.09</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>3.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057744</td>\n",
       "      <td>266.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.89436</td>\n",
       "      <td>1.654566</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AbsHum_015m  BarPresIn_015m  BarPresMb_015m  DewPtC_015m  \\\n",
       "2017-01-01 00:00:00          6.0           29.09      985.200012          3.1   \n",
       "2017-01-01 00:15:00      6.02116        29.08968      985.203247     3.208987   \n",
       "2017-01-01 00:30:00     6.045611       29.089455      985.200134     3.290628   \n",
       "2017-01-01 00:45:00     6.072257       29.089504       985.19696     3.351955   \n",
       "2017-01-01 01:00:00          6.1           29.09      985.200012          3.4   \n",
       "\n",
       "                     DewPtF_015m   DT_030m  MixHeight_015m  MixRatio_015m  \\\n",
       "2017-01-01 00:00:00    37.700001       0.0           800.0       0.004881   \n",
       "2017-01-01 00:15:00    37.743874  0.015151      685.605896       0.004897   \n",
       "2017-01-01 00:30:00    37.810856  0.017316      627.120972       0.004913   \n",
       "2017-01-01 00:45:00    37.897408  0.010822      610.075623       0.004929   \n",
       "2017-01-01 01:00:00         38.0       0.0           620.0       0.004947   \n",
       "\n",
       "                     PkWSpdMph_015m  PkWSpdMph_030m  ...  VWind_030m  \\\n",
       "2017-01-01 00:00:00             6.7            10.2  ...   -0.171487   \n",
       "2017-01-01 00:15:00        6.473885         8.82041  ...   -0.149512   \n",
       "2017-01-01 00:30:00        6.141582        7.728683  ...   -0.120539   \n",
       "2017-01-01 00:45:00        5.738489        6.897614  ...   -0.088604   \n",
       "2017-01-01 01:00:00             5.3             6.3  ...   -0.057744   \n",
       "\n",
       "                      WDir_015m   WDir_030m  WElev_015m  WElev_030m  \\\n",
       "2017-01-01 00:00:00       261.0       265.0         0.2         0.5   \n",
       "2017-01-01 00:15:00  259.699219  263.712219   -0.596983    0.469096   \n",
       "2017-01-01 00:30:00  260.691956  264.206818   -1.214409    0.287896   \n",
       "2017-01-01 00:45:00  263.088715  265.848022   -1.674631    0.012747   \n",
       "2017-01-01 01:00:00       266.0       268.0        -2.0        -0.3   \n",
       "\n",
       "                     WSpdMph_015m  WSpdMph_030m  WSpdMs_015m  WSpdMs_030m  \\\n",
       "2017-01-01 00:00:00           2.5           4.4      1.11795     1.967592   \n",
       "2017-01-01 00:15:00      2.325163      4.172241     1.039766     1.865743   \n",
       "2017-01-01 00:30:00      2.187686      3.984347      0.97829      1.78172   \n",
       "2017-01-01 00:45:00      2.081367      3.829279     0.930745     1.712377   \n",
       "2017-01-01 01:00:00           2.0           3.7      0.89436     1.654566   \n",
       "\n",
       "                     WSpdRatio030m015m_015m  \n",
       "2017-01-01 00:00:00                    1.76  \n",
       "2017-01-01 00:15:00                 1.80243  \n",
       "2017-01-01 00:30:00                1.829682  \n",
       "2017-01-01 00:45:00                1.844593  \n",
       "2017-01-01 01:00:00                    1.85  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate gaps created when making 60-min timeseries to 15-min timeseries\n",
    "for df in tower_dfs_60m_5:\n",
    "    df[df.columns] = df[df.columns].interpolate(method='cubicspline', \n",
    "                                                limit=3, # fill max 3 consecutive NaNs\n",
    "                                                limit_direction='both') \n",
    "tower_dfs_60m_5[0].head(5)\n",
    "# tower_dfs_60m_5[0].loc['2022-09-01 00:15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b054e3c-94d2-4719-9edf-ae49a0820831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tower #0\n",
      "Tower #1\n",
      "Tower #2\n",
      "Tower #3\n",
      "Tower #4\n",
      "Tower #5\n"
     ]
    }
   ],
   "source": [
    "# make sure all necessary columns are present for gap-filling\n",
    "tower_dfs_60m_6 = calc_missing_cols(tower_dfs_60m_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3b39ea9-c12c-4368-8ab8-4859aef5a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns of-interest (oi)\n",
    "cols_oi = ['TempC', \n",
    "           'PrecipIn', \n",
    "           'RelHum', 'AbsHum', \n",
    "           'WDir', \n",
    "           'WSpdMph', 'VSSpdMph', 'PkWSpdMph',\n",
    "           'Sigma', 'SigPhi', \n",
    "           'SolarRadWm2', \n",
    "           'BarPresMb']\n",
    "\n",
    "# drop columns we don't need\n",
    "tower_dfs_60m_7 = []\n",
    "for df in tower_dfs_60m_6:\n",
    "\n",
    "    colnames = df.columns\n",
    "    heights = set([colname.split('_')[1] for colname in colnames])\n",
    "\n",
    "    temp_list = []\n",
    "    for height in heights:\n",
    "        cols = [f'{x}_{height}' for x in cols_oi]\n",
    "        temp_list.append(cols)\n",
    "    temp_list = [x for sublst in temp_list for x in sublst]\n",
    "          \n",
    "    # check for these columns\n",
    "    col_list = []\n",
    "    for col in colnames:\n",
    "        if col in temp_list:\n",
    "            col_list.append(col)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    df = df[col_list]\n",
    "    tower_dfs_60m_7.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4d49044-449b-4802-be0c-d19af3561fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set datetimes\n",
    "tower_dfs_60m_8 = []\n",
    "for df, tower in zip(tower_dfs_60m_7, towers_of_interest):\n",
    "    df.index.name = 'datetimeET'\n",
    "    df.index = df.index.tz_localize('US/Eastern', ambiguous='NaT', nonexistent='NaT')\n",
    "    df = df[df.index.notna()]\n",
    "    df['timestampUTC'] = df.index.tz_convert('UTC').strftime('%Y%m%d%H%M%S')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.set_index('timestampUTC')\n",
    "    tower_dfs_60m_8.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2193a7d5-9736-4e5e-84f6-9a281b655e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>PrecipIn_015m</th>\n",
       "      <th>RelHum_015m</th>\n",
       "      <th>Sigma_015m</th>\n",
       "      <th>Sigma_030m</th>\n",
       "      <th>SigPhi_015m</th>\n",
       "      <th>SigPhi_030m</th>\n",
       "      <th>TempC_015m</th>\n",
       "      <th>TempC_030m</th>\n",
       "      <th>VSSpdMph_015m</th>\n",
       "      <th>VSSpdMph_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestampUTC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20170101050000</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170101051500</th>\n",
       "      <td>6.021160</td>\n",
       "      <td>985.203247</td>\n",
       "      <td>6.473885</td>\n",
       "      <td>8.820410</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>97.333931</td>\n",
       "      <td>27.355656</td>\n",
       "      <td>14.914644</td>\n",
       "      <td>15.871311</td>\n",
       "      <td>10.189119</td>\n",
       "      <td>3.710002</td>\n",
       "      <td>3.764628</td>\n",
       "      <td>-0.099206</td>\n",
       "      <td>-0.098456</td>\n",
       "      <td>259.699219</td>\n",
       "      <td>263.712219</td>\n",
       "      <td>2.325163</td>\n",
       "      <td>4.172241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170101053000</th>\n",
       "      <td>6.045611</td>\n",
       "      <td>985.200134</td>\n",
       "      <td>6.141582</td>\n",
       "      <td>7.728683</td>\n",
       "      <td>0.035806</td>\n",
       "      <td>97.299492</td>\n",
       "      <td>28.260035</td>\n",
       "      <td>14.289950</td>\n",
       "      <td>15.693998</td>\n",
       "      <td>9.653637</td>\n",
       "      <td>3.791788</td>\n",
       "      <td>3.816717</td>\n",
       "      <td>-0.099093</td>\n",
       "      <td>-0.098235</td>\n",
       "      <td>260.691956</td>\n",
       "      <td>264.206818</td>\n",
       "      <td>2.187686</td>\n",
       "      <td>3.984347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AbsHum_015m  BarPresMb_015m  PkWSpdMph_015m  PkWSpdMph_030m  \\\n",
       "timestampUTC                                                                  \n",
       "20170101050000     6.000000      985.200012        6.700000       10.200000   \n",
       "20170101051500     6.021160      985.203247        6.473885        8.820410   \n",
       "20170101053000     6.045611      985.200134        6.141582        7.728683   \n",
       "\n",
       "                PrecipIn_015m  RelHum_015m  Sigma_015m  Sigma_030m  \\\n",
       "timestampUTC                                                         \n",
       "20170101050000       0.040000    97.400002   25.400000   15.300000   \n",
       "20170101051500       0.038205    97.333931   27.355656   14.914644   \n",
       "20170101053000       0.035806    97.299492   28.260035   14.289950   \n",
       "\n",
       "                SigPhi_015m  SigPhi_030m  TempC_015m  TempC_030m  \\\n",
       "timestampUTC                                                       \n",
       "20170101050000    15.700000    10.600000    3.600000    3.700000   \n",
       "20170101051500    15.871311    10.189119    3.710002    3.764628   \n",
       "20170101053000    15.693998     9.653637    3.791788    3.816717   \n",
       "\n",
       "                VSSpdMph_015m  VSSpdMph_030m   WDir_015m   WDir_030m  \\\n",
       "timestampUTC                                                           \n",
       "20170101050000      -0.100000      -0.100000  261.000000  265.000000   \n",
       "20170101051500      -0.099206      -0.098456  259.699219  263.712219   \n",
       "20170101053000      -0.099093      -0.098235  260.691956  264.206818   \n",
       "\n",
       "                WSpdMph_015m  WSpdMph_030m  \n",
       "timestampUTC                                \n",
       "20170101050000      2.500000      4.400000  \n",
       "20170101051500      2.325163      4.172241  \n",
       "20170101053000      2.187686      3.984347  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_60m_8[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fc6a0fc-2bb8-4be7-ad1d-5b496d9b3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, tower in zip(tower_dfs_60m_8, towers_of_interest):\n",
    "    output_dir = '../data/met_towers_2017-2022_hourly-qc'\n",
    "    os.makedirs(output_dir, exist_ok=True)   # ← create it if it doesn’t exist\n",
    "    \n",
    "    # now it will succeed\n",
    "    df = df.fillna(-999).astype('float32')\n",
    "    df.to_csv(\n",
    "        os.path.join(output_dir, f'{tower}_2017-2022_hourly-qc.csv'),\n",
    "        encoding='utf-8-sig'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f86443-d36e-498f-a79b-4002aff5f6ca",
   "metadata": {},
   "source": [
    "---\n",
    "# 15-minute data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3aee2-e123-41c7-a317-a1713a9e4d33",
   "metadata": {},
   "source": [
    "### 1. Load 15-minute interannual tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7724e5-158f-42e2-96a6-b3df85103231",
   "metadata": {},
   "outputs": [],
   "source": [
    "towers_of_interest = ['TOWA', 'TOWB', 'TOWD', 'TOWF', 'TOWS', 'TOWY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08bcb58c-ec52-4b02-acba-7cbe7dc00618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOWA\n",
      "TOWB\n",
      "TOWD\n",
      "TOWF\n",
      "TOWS\n",
      "TOWY\n"
     ]
    }
   ],
   "source": [
    "# read 15-min multiannual data\n",
    "tower_dfs_15m = []\n",
    "for tname in towers_of_interest:\n",
    "    print(tname)\n",
    "    filename = f'{MN_DATA_DIR}/{tname}_2017-2022.csv'\n",
    "    df = pd.read_csv(filename, header=0, index_col=0, na_values=['-999.0', '#DIV/0!', -999])\n",
    "    df.index = pd.to_datetime(df.index, format='mixed').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df.columns = df.columns.str.strip()\n",
    "    tower_dfs_15m.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5c96b-8d0f-4a25-ac62-e5200022a9dc",
   "metadata": {},
   "source": [
    "### 2. Fill gaps in 15-minute time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a659d86a-035a-41ec-9d82-fe08d127d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize timesteps\n",
    "tower_dfs_15m_2 = standardize_dateranges(tower_dfs_15m, '15Min', '2017-01-01 00:00:00', '2022-12-31 23:45:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4296b1-cc38-40fe-b9ed-1cd4074652a9",
   "metadata": {},
   "source": [
    "### 3. Calculate missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "055e89a0-67eb-4136-8136-d516332c3ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tower #0\n",
      "Tower #1\n",
      "Tower #2\n",
      "Tower #3\n",
      "Tower #4\n",
      "Tower #5\n"
     ]
    }
   ],
   "source": [
    "tower_dfs_15m_3 = calc_missing_cols(tower_dfs_15m_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b10d84-f0fa-4f03-9e36-00560e94dba7",
   "metadata": {},
   "source": [
    "### 4. Select variables of interest and drop unneccessary ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "851d0a0a-d74e-4e50-a594-721aa3cb9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_dfs_15m_4 = []\n",
    "for df in tower_dfs_15m_3:\n",
    "\n",
    "    colnames = df.columns\n",
    "    heights = set([colname.split('_')[1] for colname in colnames])\n",
    "\n",
    "    temp_list = []\n",
    "    for height in heights:\n",
    "        cols = [f'{x}_{height}' for x in cols_oi]\n",
    "        temp_list.append(cols)\n",
    "    temp_list = [x for sublst in temp_list for x in sublst]\n",
    "          \n",
    "    # check for these columns\n",
    "    col_list = []\n",
    "    for col in colnames:\n",
    "        if col in temp_list:\n",
    "            col_list.append(col)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    df = df[col_list]\n",
    "    tower_dfs_15m_4.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55a77c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \"original\" data that are lightly quality controlled\n",
    "for df, tower in zip(tower_dfs_15m_4, towers_of_interest):\n",
    "    out_df = df.copy()\n",
    "    out_df.index.name = 'datetimeET'\n",
    "    out_df.index = out_df.index.tz_localize('US/Eastern', ambiguous='NaT', nonexistent='NaT')\n",
    "    out_df = out_df[out_df.index.notna()]\n",
    "    out_df['timestampUTC'] = out_df.index.tz_convert('UTC').strftime('%Y%m%d%H%M%S')\n",
    "    out_df = out_df.reset_index(drop=True)\n",
    "    out_df = out_df.set_index('timestampUTC')\n",
    "\n",
    "    output_dir = '../data/met_towers_2017-2022_original-qc'\n",
    "    os.makedirs(output_dir, exist_ok=True)   # ← create it if it doesn’t exist\n",
    "    \n",
    "    # now it will succeed\n",
    "    out_df = out_df.fillna(-999).astype('float32')\n",
    "    out_df.to_csv(\n",
    "        os.path.join(output_dir, f'{tower}_2017-2022_original-qc.csv'),\n",
    "        encoding='utf-8-sig'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f227b6-5303-48b5-9f85-a49d01ff84f3",
   "metadata": {},
   "source": [
    "### 5(a). Remove constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feb07b4f-588b-43e6-8379-bc27173da8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_long_repeats(series, column_name):\n",
    "    \n",
    "    if column_name.startswith('PrecipIn') or column_name.startswith('SolarRadWm2'):\n",
    "        # Only consider non-zero values for replacement\n",
    "        mask = (series != series.shift()) | (series == 0)\n",
    "    else:\n",
    "        # Identify repeated values\n",
    "        mask = series != series.shift()\n",
    "        \n",
    "    # Find the start of each group\n",
    "    group_starts = mask.cumsum()\n",
    "    # Group by these start points\n",
    "    groups = series.groupby(group_starts)\n",
    "    # Calculate the duration of each group\n",
    "    duration = groups.transform('size') * 15  # Duration in minutes (15-minute intervals)\n",
    "    # Replace values with NaN if duration is greater than or equal to 6 hours (360 minutes)\n",
    "    if column_name.startswith('PrecipIn'):\n",
    "        series[(duration >= 360) & (series != 0)] = np.nan\n",
    "    else:\n",
    "        series[duration >= 360] = np.nan\n",
    "    \n",
    "    return series\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "tower_dfs_15m_5 = []\n",
    "for df in tower_dfs_15m_4:\n",
    "    df = df.apply(lambda x: replace_long_repeats(x, x.name))\n",
    "    tower_dfs_15m_5.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b37de3-62ee-49ca-b43c-72d78ebdcc41",
   "metadata": {},
   "source": [
    "### 5(b). Mask values outside of normal range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "020a84e2-4c26-43f1-a2b9-229a18422709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TempF</th>\n",
       "      <td>-30.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempC</th>\n",
       "      <td>-30.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelHum</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPtF</th>\n",
       "      <td>-36.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DewPtC</th>\n",
       "      <td>-35.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Min    Max\n",
       "Sensor             \n",
       "TempF  -30.0  110.0\n",
       "TempC  -30.0   45.0\n",
       "RelHum   0.0  100.0\n",
       "DewPtF -36.0   82.0\n",
       "DewPtC -35.0   28.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oor.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c831558-d675-4fe7-88c3-ff23c2c69e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe by adding associated min/max to variables (where applicable)\n",
    "tower_dfs_15m_6 = []\n",
    "for df in tower_dfs_15m_5:\n",
    "    temp = df.T.reset_index().T.reset_index() # pushes header down into row\n",
    "    temp = temp.set_index('index', drop=True) # puts timeseries index back in place\n",
    "    colnames = temp.loc['index'].to_list() # get variable names\n",
    "    temp.columns = [x.split('_')[0] for x in colnames] # get first word from variable name\n",
    "    out_df = temp.T # transpose variables from columns to indices\n",
    "    out_df = out_df.rename(columns=dict(index='orig_name'))\n",
    "    out_df = out_df.merge(oor, how='left', left_index=True, right_index=True) # join OOR table to get limits\n",
    "    tower_dfs_15m_6.append(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa336340-b634-4d5f-add2-aa0168b8e2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_name</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-01 00:15:00</th>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <th>2017-01-01 00:45:00</th>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <th>2017-01-01 01:15:00</th>\n",
       "      <th>2017-01-01 01:30:00</th>\n",
       "      <th>2017-01-01 01:45:00</th>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-12-31 22:00:00</th>\n",
       "      <th>2022-12-31 22:15:00</th>\n",
       "      <th>2022-12-31 22:30:00</th>\n",
       "      <th>2022-12-31 22:45:00</th>\n",
       "      <th>2022-12-31 23:00:00</th>\n",
       "      <th>2022-12-31 23:15:00</th>\n",
       "      <th>2022-12-31 23:30:00</th>\n",
       "      <th>2022-12-31 23:45:00</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WDir</th>\n",
       "      <td>WDir_015m</td>\n",
       "      <td>268.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>248.5</td>\n",
       "      <td>306.5</td>\n",
       "      <td>120.699997</td>\n",
       "      <td>273.600006</td>\n",
       "      <td>253.0</td>\n",
       "      <td>294.100006</td>\n",
       "      <td>206.300003</td>\n",
       "      <td>212.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDir</th>\n",
       "      <td>WDir_030m</td>\n",
       "      <td>274.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>263.399994</td>\n",
       "      <td>267.399994</td>\n",
       "      <td>248.899994</td>\n",
       "      <td>263.700012</td>\n",
       "      <td>259.899994</td>\n",
       "      <td>268.0</td>\n",
       "      <td>284.200012</td>\n",
       "      <td>275.600006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSpdMph</th>\n",
       "      <td>WSpdMph_015m</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSpdMph</th>\n",
       "      <td>WSpdMph_030m</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PrecipIn</th>\n",
       "      <td>PrecipIn_015m</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              orig_name 2017-01-01 00:00:00 2017-01-01 00:15:00  \\\n",
       "WDir          WDir_015m               268.0               252.0   \n",
       "WDir          WDir_030m               274.0               264.0   \n",
       "WSpdMph    WSpdMph_015m                 2.2                 2.4   \n",
       "WSpdMph    WSpdMph_030m                 4.4                 4.7   \n",
       "PrecipIn  PrecipIn_015m            0.015748            0.011811   \n",
       "\n",
       "         2017-01-01 00:30:00 2017-01-01 00:45:00 2017-01-01 01:00:00  \\\n",
       "WDir                   255.0               268.0               268.0   \n",
       "WDir                   260.0               263.0               274.0   \n",
       "WSpdMph                  2.8                 2.5                 2.2   \n",
       "WSpdMph                  4.3                 4.2                 4.0   \n",
       "PrecipIn            0.011811            0.007874            0.007874   \n",
       "\n",
       "         2017-01-01 01:15:00 2017-01-01 01:30:00 2017-01-01 01:45:00  \\\n",
       "WDir                   257.0               273.0               266.0   \n",
       "WDir                   257.0               275.0               268.0   \n",
       "WSpdMph                  2.6                 1.5                 1.7   \n",
       "WSpdMph                  4.0                 3.4                 3.3   \n",
       "PrecipIn            0.019685            0.003937            0.003937   \n",
       "\n",
       "         2017-01-01 02:00:00  ... 2022-12-31 22:00:00 2022-12-31 22:15:00  \\\n",
       "WDir                   279.0  ...               248.5               306.5   \n",
       "WDir                   272.0  ...          263.399994          267.399994   \n",
       "WSpdMph                  1.8  ...                 1.0                 0.6   \n",
       "WSpdMph                  3.4  ...                 2.9                 2.3   \n",
       "PrecipIn            0.007874  ...                 0.0                 0.0   \n",
       "\n",
       "         2022-12-31 22:30:00 2022-12-31 22:45:00 2022-12-31 23:00:00  \\\n",
       "WDir              120.699997          273.600006               253.0   \n",
       "WDir              248.899994          263.700012          259.899994   \n",
       "WSpdMph                  0.4                 0.2                 0.7   \n",
       "WSpdMph                  2.6                 2.5                 3.1   \n",
       "PrecipIn                 0.0                 0.0                 0.0   \n",
       "\n",
       "         2022-12-31 23:15:00 2022-12-31 23:30:00 2022-12-31 23:45:00  Min  \\\n",
       "WDir              294.100006          206.300003               212.5  0.0   \n",
       "WDir                   268.0          284.200012          275.600006  0.0   \n",
       "WSpdMph                  0.4                 0.4                 1.0  0.0   \n",
       "WSpdMph                  2.9                 3.2                 2.2  0.0   \n",
       "PrecipIn                 0.0                 0.0                 0.0  0.0   \n",
       "\n",
       "            Max  \n",
       "WDir      360.0  \n",
       "WDir      360.0  \n",
       "WSpdMph    50.0  \n",
       "WSpdMph    50.0  \n",
       "PrecipIn    inf  \n",
       "\n",
       "[5 rows x 210339 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_15m_6[0].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b68a868-4ece-4277-b569-74c68537488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask values outside of limits\n",
    "tower_dfs_15m_7 = []\n",
    "for df in tower_dfs_15m_6:\n",
    "    out_df = df.apply(lambda row: mask_oor(row), axis=1)\n",
    "    out_df.index = df['orig_name']\n",
    "    out_df = out_df.T\n",
    "    out_df.index = pd.to_datetime(out_df.index)\n",
    "    tower_dfs_15m_7.append(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077b856-59ae-4679-82d8-9b621a7cc241",
   "metadata": {},
   "source": [
    "### 6. Mask values that change too rapidly in an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "501bfb78-c4cb-4382-9ecc-2ee67550a8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Type</th>\n",
       "      <th>Units</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TempF</th>\n",
       "      <td>Hourly Rate of Change Error</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TempC</th>\n",
       "      <td>Hourly Rate of Change Error</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelHum</th>\n",
       "      <td>Hourly Rate of Change Error</td>\n",
       "      <td>percent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error Type    Units  Min   Max\n",
       "Sensor                                                 \n",
       "TempF   Hourly Rate of Change Error        F  NaN  10.0\n",
       "TempC   Hourly Rate of Change Error        C  NaN   5.0\n",
       "RelHum  Hourly Rate of Change Error  percent  NaN  25.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "506b0825-4005-4b78-946b-027d3699e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask values that change too rapidly in an hour\n",
    "tower_dfs_15m_8 = []\n",
    "for df in tower_dfs_15m_7:\n",
    "    out_df = mask_rapid_roc(df)\n",
    "    tower_dfs_15m_8.append(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84317c4f-00fb-456f-be9f-42cf90554a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>orig_name</th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>RelHum_015m</th>\n",
       "      <th>Sigma_015m</th>\n",
       "      <th>Sigma_030m</th>\n",
       "      <th>SigPhi_015m</th>\n",
       "      <th>SigPhi_030m</th>\n",
       "      <th>TempC_015m</th>\n",
       "      <th>TempC_030m</th>\n",
       "      <th>VSSpdMph_015m</th>\n",
       "      <th>VSSpdMph_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "      <th>PrecipIn_015m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>985.299988</td>\n",
       "      <td>5.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>268.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:15:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>985.299988</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>97.300003</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>252.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>255.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "orig_name            AbsHum_015m  BarPresMb_015m  PkWSpdMph_015m  \\\n",
       "2017-01-01 00:00:00          6.0      985.299988             5.9   \n",
       "2017-01-01 00:15:00          6.0      985.299988             6.7   \n",
       "2017-01-01 00:30:00          6.0      985.200012             6.0   \n",
       "\n",
       "orig_name            PkWSpdMph_030m  RelHum_015m  Sigma_015m  Sigma_030m  \\\n",
       "2017-01-01 00:00:00            10.2    97.400002   26.500000        15.5   \n",
       "2017-01-01 00:15:00             7.7    97.300003   19.299999        13.9   \n",
       "2017-01-01 00:30:00             6.8    97.400002   25.299999        15.0   \n",
       "\n",
       "orig_name            SigPhi_015m  SigPhi_030m  TempC_015m  TempC_030m  \\\n",
       "2017-01-01 00:00:00         18.9         12.6         3.6         3.6   \n",
       "2017-01-01 00:15:00         14.3          9.8         3.6         3.6   \n",
       "2017-01-01 00:30:00         13.6         11.0         3.6         3.7   \n",
       "\n",
       "orig_name            VSSpdMph_015m  VSSpdMph_030m  WDir_015m  WDir_030m  \\\n",
       "2017-01-01 00:00:00            0.0      -0.100000      268.0      274.0   \n",
       "2017-01-01 00:15:00            0.0      -0.100000      252.0      264.0   \n",
       "2017-01-01 00:30:00           -0.2       0.000064      255.0      260.0   \n",
       "\n",
       "orig_name            WSpdMph_015m  WSpdMph_030m  PrecipIn_015m  \n",
       "2017-01-01 00:00:00           2.2           4.4       0.015748  \n",
       "2017-01-01 00:15:00           2.4           4.7       0.011811  \n",
       "2017-01-01 00:30:00           2.8           4.3       0.011811  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_15m_8[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05aa6a99-e533-4f7d-8920-c8ee81d9ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AbsHum_015m', 'BarPresMb_015m', 'PkWSpdMph_015m', 'PkWSpdMph_030m',\n",
       "       'RelHum_015m', 'Sigma_015m', 'Sigma_030m', 'SigPhi_015m', 'SigPhi_030m',\n",
       "       'TempC_015m', 'TempC_030m', 'VSSpdMph_015m', 'VSSpdMph_030m',\n",
       "       'WDir_015m', 'WDir_030m', 'WSpdMph_015m', 'WSpdMph_030m',\n",
       "       'PrecipIn_015m'],\n",
       "      dtype='object', name='orig_name')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_15m_8[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56c96268-aadb-461b-aaba-8c1b10732b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single-tower rolling window\n",
    "# # outliers are 3 standard deviations from window mean\n",
    "# def rolling_window_outlier_detection(data, window_size, zscore_threshold):\n",
    "#     rolling_mean = data.rolling(window=window_size, center=True).mean()\n",
    "#     rolling_std = data.rolling(window=window_size, center=True).std()\n",
    "#     outliers = (data - rolling_mean).abs() > (zscore_threshold * rolling_std)\n",
    "#     return rolling_mean, outliers\n",
    "\n",
    "# def plot_variable_data_with_outliers(df, tname, var, window_sizes, zscore_threshold):\n",
    "    \n",
    "#     for column in df.columns:\n",
    "        \n",
    "#         if column.startswith(var):\n",
    "\n",
    "#             all_outliers = {}\n",
    "#             for window_size in window_sizes:\n",
    "                \n",
    "#                 plt.figure(figsize=(12, 6))\n",
    "                \n",
    "#                 # Calculate rolling mean and detect outliers\n",
    "#                 rolling_mean, outliers = rolling_window_outlier_detection(df[column], window_size, zscore_threshold)\n",
    "                \n",
    "#                 # Plot original data\n",
    "#                 plt.plot(df.index, df[column], label='Original Data', alpha=0.5, zorder=1)\n",
    "#                 plt.plot(rolling_mean.index, rolling_mean, label=f'Rolling Mean ({window_size})', color='orange', zorder=2)\n",
    "                \n",
    "#                 outlier_points = df[column][outliers]\n",
    "#                 plt.scatter(df.index[outliers], outlier_points, color='red', label='Outliers', zorder=3)\n",
    "                \n",
    "#                 plt.title(f'{tname}: {column}')\n",
    "#                 plt.xlim(datetime(2017, 1, 1), datetime(2022, 12, 31))\n",
    "#                 plt.legend(loc='upper left')\n",
    "#                 plt.show()\n",
    "\n",
    "#                 all_outliers[window_size] = outlier_points.index\n",
    "\n",
    "#             return all_outliers\n",
    "\n",
    "# # Example usage with tower_dfs_15m_8 and towers_of_interest assumed to be defined\n",
    "# for df, tname in zip(towers_data, tower_names):\n",
    "#     if tname == tower:\n",
    "#         single_tower_outliers = plot_variable_data_with_outliers(df, tname, var, window_sizes, zscore_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7eb646f-ada9-4a38-9e5c-8aac9c3ff30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling window outlier detection function for non-circular data\n",
    "def rolling_window_outlier_detection(data, window_size, z_threshold):\n",
    "    rolling_means = data.rolling(window=window_size, center=True).mean()\n",
    "    rolling_stds = data.rolling(window=window_size, center=True).std()\n",
    "    \n",
    "    overall_mean = rolling_means.mean(axis=1)\n",
    "    overall_std = rolling_stds.mean(axis=1)\n",
    "    \n",
    "    outliers = pd.DataFrame(index=data.index, columns=data.columns, dtype=bool)\n",
    "    \n",
    "    for column in data.columns:\n",
    "        individual_zscores = (data[column] - rolling_means[column]) / rolling_stds[column]\n",
    "        combined_zscores = (data[column] - overall_mean) / overall_std\n",
    "        \n",
    "        individual_outliers = np.abs(individual_zscores) > z_threshold\n",
    "        combined_outliers = np.abs(combined_zscores) > z_threshold\n",
    "        \n",
    "        confirmed_outliers = individual_outliers & combined_outliers\n",
    "        outliers[column] = confirmed_outliers\n",
    "\n",
    "    return outliers, rolling_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e7d8c93-d473-48ef-8e41-be282a014def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated extract variable data by height function\n",
    "def extract_variable_data_by_height(towers_data, tower_names):\n",
    "    combined_data = {}\n",
    "    \n",
    "    # Define tower groups\n",
    "    group1 = ['TOWA', 'TOWB', 'TOWD']\n",
    "    group2 = ['TOWF', 'TOWS']\n",
    "    group3 = ['TOWY']\n",
    "    \n",
    "    # Helper function to determine group\n",
    "    def get_group(tower_name):\n",
    "        if tower_name in group1:\n",
    "            return 'group1'\n",
    "        elif tower_name in group2:\n",
    "            return 'group2'\n",
    "        elif tower_name in group3:\n",
    "            return 'group3'\n",
    "        else:\n",
    "            return 'others'\n",
    "\n",
    "    # Combine data by height and group\n",
    "    for i, (tower_df, tower_name) in enumerate(zip(towers_data, tower_names)):\n",
    "        for column in tower_df.columns:\n",
    "            variable_type, height = column.split('_')\n",
    "            group = get_group(tower_name)\n",
    "            combined_key = (variable_type, height, group)\n",
    "            col_name = f\"{tower_name}_{height}\"\n",
    "            \n",
    "            if combined_key not in combined_data:\n",
    "                combined_data[combined_key] = []\n",
    "            combined_data[combined_key].append(tower_df[column].rename(col_name))\n",
    "    \n",
    "    # Concatenate data for each combined key\n",
    "    for key in combined_data.keys():\n",
    "        combined_data[key] = pd.concat(combined_data[key], axis=1)\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41ec24e2-f044-409b-85a2-f18b5ea987d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot variable data for window sizes with outlier detection\n",
    "def plot_variable_data_for_window_sizes(towers_data, tower_names, var, tower, window_sizes, z_threshold):\n",
    "    combined_data = extract_variable_data_by_height(towers_data, tower_names)\n",
    "\n",
    "    all_outliers_heights = {}\n",
    "    for height in set(col.split('_')[1] for col in towers_data[tower_names.index(tower)].columns if col.startswith(var)):\n",
    "        \n",
    "        column = f\"{tower}_{height}\"\n",
    "        \n",
    "        # Choose the appropriate key for the specified tower\n",
    "        group = 'others'\n",
    "        if tower in ['TOWA', 'TOWB', 'TOWD']:\n",
    "            group = 'group1'\n",
    "        elif tower in ['TOWF', 'TOWS']:\n",
    "            group = 'group2'\n",
    "        elif tower == 'TOWY':\n",
    "            group = 'group3'\n",
    "        \n",
    "        key = (var, height, group)\n",
    "        \n",
    "        if key not in combined_data:\n",
    "            continue\n",
    "        \n",
    "        data = combined_data[key]\n",
    "        \n",
    "        if f\"{tower}_{height}\" not in data.columns:\n",
    "            continue\n",
    "        \n",
    "        towers_used = []\n",
    "        for tower_name in tower_names:\n",
    "            if f\"{tower_name}_{height}\" in data.columns:\n",
    "                towers_used.append(f\"{tower_name}_{height}\")\n",
    "        \n",
    "        all_outliers = {}\n",
    "        for window_size in window_sizes:\n",
    "\n",
    "            # Handle other variables\n",
    "            outliers, rolling_means = rolling_window_outlier_detection(data, window_size, z_threshold)\n",
    "            \n",
    "            fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            ax1.plot(data.index, data[column], label='Original Data', alpha=0.5, zorder=1)\n",
    "            ax1.plot(rolling_means.index, rolling_means[column], label=f'Rolling Mean ({window_size})', color='orange', zorder=2)\n",
    "            outlier_points = data[column][outliers[column]]\n",
    "            ax1.scatter(outlier_points.index, outlier_points, color='red', label='Outliers', zorder=3)\n",
    "            ax1.set_ylabel(var)\n",
    "            ax1.set_xlabel('Time')\n",
    "            ax1.legend(loc='lower left')\n",
    "\n",
    "            towers_info = '\\n'.join(towers_used)\n",
    "            plt.text(0.02, 0.95, f'Data Leveraged:\\n{towers_info}', transform=plt.gca().transAxes,\n",
    "                     fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', edgecolor='black', pad=5))\n",
    "\n",
    "            plt.title(f'{tower}: {var}_{height}')\n",
    "            plt.xlim(datetime(2017, 1, 1), datetime(2022, 12, 31))\n",
    "            plt.show()\n",
    "\n",
    "            all_outliers[window_size] = outlier_points.index\n",
    "\n",
    "        all_outliers_heights[height] = all_outliers\n",
    "        \n",
    "    return all_outliers_heights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143fd4f2-5080-401e-9eb5-7208ab290ded",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70a70996-6f58-4a58-be33-51972767a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test z_thresholds and window sizes\n",
    "# towers_data = tower_dfs_15m_8\n",
    "# tower_names = towers_of_interest\n",
    "# var = 'RelHum'\n",
    "# tower = 'TOWD'\n",
    "# z_threshold = 4\n",
    "# window_sizes = ['1H', '3H', '6H', '12H',\n",
    "#                 '3H', '4H', '5H', '6H',\n",
    "#                 '1D', '3D', '6D', '12D',\n",
    "#                 '30D', '60D', '90D', '120D']\n",
    "\n",
    "# multi_tower_outliers = plot_variable_data_for_window_sizes(towers_data, tower_names, var, tower, window_sizes, z_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd087861-ca77-4da8-887c-0cb0f5395ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_sample(datetimes, proportion):\n",
    "#     sample_size = int(len(datetimes) * proportion)\n",
    "#     return random.sample(datetimes, sample_size)\n",
    "\n",
    "# def sample_dict(dict, proportion=0.2, selected_key=None):\n",
    "        \n",
    "#     key = selected_key\n",
    "#     if selected_key:\n",
    "\n",
    "#         dict = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in dict[key]]\n",
    "        \n",
    "#         dict_sample = get_random_sample(dict, proportion)\n",
    "        \n",
    "#         print(f\"Key: {key}\")\n",
    "#         print(f\"Sampled outliers in dict: {sorted(dict_sample)}\")\n",
    "#         print(f\"Number of outliers in dict: {len(sorted(dict))}\")\n",
    "#         print(f\"All outliers in dict: {sorted(dict)}\")\n",
    "#     else:\n",
    "#         print(f\"Key: {key} is not present in dict\")\n",
    "\n",
    "# # Compare the dictionaries with a sample size of 5 and an optional selected key\n",
    "\n",
    "# sample_dict(multi_tower_outliers['015m'], 0.2, '3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a3ce8f0-a5d6-4b96-a96a-876463aaf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_cartesian_coordinates(wind_speed, wind_dir_deg):\n",
    "#     wind_dir_rad = np.deg2rad(wind_dir_deg)\n",
    "#     U = (-wind_speed * np.sin(wind_dir_rad)).astype(np.float32)  # Negative sign to align with meteorological convention\n",
    "#     V = (-wind_speed * np.cos(wind_dir_rad)).astype(np.float32)  # Negative sign to align with meteorological convention\n",
    "#     return U, V\n",
    "\n",
    "# def plot_wind_data(towers_data, tower_names, tower, eps=0.95, min_samples=2):\n",
    "    \n",
    "#     combined_data = extract_variable_data_by_height(towers_data, tower_names)\n",
    "#     outlier_datetimes_by_height = []\n",
    "    \n",
    "#     for height in set(col.split('_')[1] for col in towers_data[tower_names.index(tower)].columns):\n",
    "\n",
    "#         # Loop thru heights (e.g., 15m and 30m)\n",
    "#         outlier_counts = defaultdict(lambda: defaultdict(list))  # Dictionary to collect outliers by datetime and tower group\n",
    "\n",
    "#         # Determine the group based on tower name\n",
    "#         if tower in ['TOWA', 'TOWB', 'TOWD']:\n",
    "#             group = 'group1'\n",
    "#         elif tower in ['TOWF', 'TOWS']:\n",
    "#             group = 'group2'\n",
    "#         elif tower == 'TOWY':\n",
    "#             group = 'group3'\n",
    "#         else:\n",
    "#             group = 'others'\n",
    "        \n",
    "#         key_wind = ('WSpdMph', height, group)\n",
    "#         key_dir = ('WDir', height, group)\n",
    "        \n",
    "#         if key_wind in combined_data and key_dir in combined_data:\n",
    "            \n",
    "#             data_wind = combined_data[key_wind]\n",
    "#             data_dir = combined_data[key_dir]\n",
    "            \n",
    "#             col = f'{tower}_{height}'\n",
    "            \n",
    "#             if col in data_wind.columns and col in data_dir.columns:\n",
    "\n",
    "#                 for towerheight in data_wind.columns:\n",
    "                \n",
    "#                     wind_speed_data = data_wind[towerheight]\n",
    "#                     wind_dir_data = data_dir[towerheight]\n",
    "\n",
    "#                     # Calculate Cartesian coordinates\n",
    "#                     U, V = calculate_cartesian_coordinates(wind_speed_data, wind_dir_data)\n",
    "                \n",
    "#                     # Remove rows with NaN values\n",
    "#                     nan_indices = np.isnan(U) | np.isnan(V)\n",
    "#                     U_clean = U[~nan_indices]\n",
    "#                     V_clean = V[~nan_indices]\n",
    "#                     if towerheight == col:\n",
    "#                         Udata = U_clean\n",
    "#                         Vdata = V_clean\n",
    "\n",
    "#                     # Perform DBSCAN clustering\n",
    "#                     print(f'Clustering {towerheight}')\n",
    "#                     X = np.column_stack((U_clean, V_clean))\n",
    "#                     clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "                \n",
    "#                     # Detect outliers\n",
    "#                     outlier_indices = clustering.labels_ == -1  # mask, -1 indicates outlier points (True)\n",
    "#                     outlier_dates = data_wind.index[~nan_indices][outlier_indices].tolist()\n",
    "#                     for date in outlier_dates:\n",
    "#                         outlier_counts[date][group].append(towerheight)\n",
    "                \n",
    "#                 # Identify points where multiple towers in the same group have outliers at the same datetime\n",
    "#                 outlier_datetimes = []\n",
    "#                 for date, towerheight in outlier_counts.items():\n",
    "#                     if col in towerheight[group]:\n",
    "#                         if len(towerheight[group]) == 1:\n",
    "#                             outlier_datetimes.append(date)\n",
    "#                 print(f'Number of outliers: {len(outlier_datetimes)}')\n",
    "\n",
    "#                 # Plot Cartesian coordinates with outliers and normal points\n",
    "#                 fig = go.Figure()\n",
    "\n",
    "#                 # Add normal points\n",
    "#                 fig.add_trace(go.Scatter(\n",
    "#                     x=Udata, \n",
    "#                     y=Vdata,\n",
    "#                     mode='markers',\n",
    "#                     marker=dict(color='blue', size=10, opacity=0.5),\n",
    "#                     hoverinfo='skip',\n",
    "#                     name='Normal Points'\n",
    "#                 ))\n",
    "                \n",
    "#                 # Add outliers\n",
    "#                 fig.add_trace(go.Scatter(\n",
    "#                     x=Udata.loc[Udata.index.isin(outlier_datetimes)], \n",
    "#                     y=Vdata.loc[Vdata.index.isin(outlier_datetimes)],\n",
    "#                     mode='markers',\n",
    "#                     marker=dict(color='red', size=10),\n",
    "#                     customdata=outlier_datetimes,\n",
    "#                     hovertemplate='Outlier Datetime: %{customdata}<br>U: %{x}<br>V: %{y}<extra></extra>',\n",
    "#                     name='Outliers'\n",
    "#                 ))\n",
    "                \n",
    "#                 # Update layout\n",
    "#                 fig.update_layout(\n",
    "#                     title=f'{tower}: Wind Speed Components at Height {height}',\n",
    "#                     xaxis_title='U (Eastward Wind Component)',\n",
    "#                     yaxis_title='V (Northward Wind Component)',\n",
    "#                     legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "#                     template='plotly_white'\n",
    "#                 )\n",
    "\n",
    "#                 plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74242c93-e983-4bc4-9e4a-871fd77433c0",
   "metadata": {},
   "source": [
    "---\n",
    "# Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a769f9-f747-417a-9e97-34a86324de16",
   "metadata": {},
   "source": [
    "### 1(a). Simple rolling window variables\n",
    "TempC, RelHum, AbsHum, RelHum, WSpdMph, PkWSpdMph, SolarRadWm2, BarPresMb\n",
    "\n",
    "The window sizes were determined by rigorous testing; not every variable should be treated the same\n",
    "1. Visually determine how many outliers I expect and when I expect most outliers to be found for a variable (testing on Tower A)\n",
    "2. Calculate the accuracy of a single-tower approach or a multi-tower leveraging approach; this number does not consider false negatives (I did not have time to manually count every single outlier); the multi-tower approach outperformed the single-tower approach every time\n",
    "3. Test 1, 3, 6, 12 hours; 1, 3, 6, 12 days; and 30, 60, 90, 120 days for the window size; test 3 standard devs and 4 standard devs as the outlier threshold\n",
    "4. Determine which variables are best suited for a rolling window approach (TempC, RelHum, AbsHum, RelHum, WSpdMph, PkWSpdMph, SolarRadWm2, BarPresMb)\n",
    "5. Determine which variables are best suited for manual outlier removal (Sigma, SigPhi, VSSpdMph)\n",
    "6. Determine which variables need a unique approach (WDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d41931b-88fa-4a0a-a0f9-0c44f4196d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling window outlier detection function for non-circular data\n",
    "def rolling_window_outlier_detection(data, window_size, z_threshold):\n",
    "    rolling_means = data.rolling(window=window_size, center=True).mean()\n",
    "    rolling_stds = data.rolling(window=window_size, center=True).std()\n",
    "    \n",
    "    overall_mean = rolling_means.mean(axis=1)\n",
    "    overall_std = rolling_stds.mean(axis=1)\n",
    "    \n",
    "    outliers = pd.DataFrame(index=data.index, columns=data.columns, dtype=bool)\n",
    "    \n",
    "    for column in data.columns:\n",
    "        individual_zscores = (data[column] - rolling_means[column]) / rolling_stds[column]\n",
    "        combined_zscores = (data[column] - overall_mean) / overall_std\n",
    "        \n",
    "        individual_outliers = np.abs(individual_zscores) > z_threshold\n",
    "        combined_outliers = np.abs(combined_zscores) > z_threshold\n",
    "        \n",
    "        confirmed_outliers = individual_outliers & combined_outliers\n",
    "        outliers[column] = confirmed_outliers\n",
    "\n",
    "    return outliers, rolling_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63216bc0-1058-4a69-8543-602c85cda588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated extract variable data by height function\n",
    "def extract_variable_data_by_height(towers_data, tower_names):\n",
    "    combined_data = {}\n",
    "    \n",
    "    # Define tower groups\n",
    "    group1 = ['TOWA', 'TOWB', 'TOWD']\n",
    "    group2 = ['TOWF', 'TOWS']\n",
    "    group3 = ['TOWY']\n",
    "    \n",
    "    # Helper function to determine group\n",
    "    def get_group(tower_name):\n",
    "        if tower_name in group1:\n",
    "            return 'group1'\n",
    "        elif tower_name in group2:\n",
    "            return 'group2'\n",
    "        elif tower_name in group3:\n",
    "            return 'group3'\n",
    "        else:\n",
    "            return 'others'\n",
    "\n",
    "    # Combine data by height and group\n",
    "    for i, (tower_df, tower_name) in enumerate(zip(towers_data, tower_names)):\n",
    "        for column in tower_df.columns:\n",
    "            variable_type, height = column.split('_')\n",
    "            group = get_group(tower_name)\n",
    "            combined_key = (variable_type, height, group)\n",
    "            col_name = f\"{tower_name}_{height}\"\n",
    "            \n",
    "            if combined_key not in combined_data:\n",
    "                combined_data[combined_key] = []\n",
    "            combined_data[combined_key].append(tower_df[column].rename(col_name))\n",
    "    \n",
    "    # Concatenate data for each combined key\n",
    "    for key in combined_data.keys():\n",
    "        combined_data[key] = pd.concat(combined_data[key], axis=1)\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ffff3e2-bc0d-49a8-a249-49a86fe4aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot variable data for window sizes with outlier detection\n",
    "def plot_variable_data_for_window_sizes(towers_data, tower_names, var, tower):\n",
    "    \n",
    "    combined_data = extract_variable_data_by_height(towers_data, tower_names)\n",
    "    all_outliers = collections.defaultdict(dict)\n",
    "    \n",
    "    for height in set(col.split('_')[1] for col in towers_data[tower_names.index(tower)].columns if col.startswith(var)):\n",
    "        \n",
    "        column = f\"{tower}_{height}\"\n",
    "        # print(tower, var, height)\n",
    "        \n",
    "        # Choose the appropriate key for the specified tower\n",
    "        group = 'others'\n",
    "        if tower in ['TOWA', 'TOWB', 'TOWD']:\n",
    "            group = 'group1'\n",
    "        elif tower in ['TOWF', 'TOWS']:\n",
    "            group = 'group2'\n",
    "        elif tower == 'TOWY':\n",
    "            group = 'group3'\n",
    "        \n",
    "        key = (var, height, group)\n",
    "        if key not in combined_data:\n",
    "            continue\n",
    "        \n",
    "        data = combined_data[key]\n",
    "        if column not in data.columns:\n",
    "            continue\n",
    "\n",
    "        # Set parameters for each variable\n",
    "        if var == 'TempC':\n",
    "            window_size = '3H'\n",
    "            z_threshold = 3\n",
    "\n",
    "        elif var == 'AbsHum':\n",
    "            window_size = '3H'\n",
    "            z_threshold = 3\n",
    "\n",
    "        elif var == 'RelHum':\n",
    "            window_size = '12H'\n",
    "            z_threshold = 4\n",
    "\n",
    "        elif var == 'WSpdMph':\n",
    "            window_size = '3H'\n",
    "            z_threshold = 3\n",
    "\n",
    "        elif var == 'PkWSpdMph':\n",
    "            window_size = '6H'\n",
    "            z_threshold = 4\n",
    "\n",
    "        elif var == 'BarPresMb':\n",
    "            window_size = '3H'\n",
    "            z_threshold = 3\n",
    "\n",
    "        elif var == 'SolarRadWm2':\n",
    "            window_size = '12H'\n",
    "            z_threshold = 4\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # print(f'Finding outliers for {var} using a window size of {window_size} and z-threshold of {z_threshold}.')\n",
    "        outliers, rolling_means = rolling_window_outlier_detection(data, window_size, z_threshold)\n",
    "        outlier_points = data[column][outliers[column]]\n",
    "        all_outliers[height] = [outlier_points.index, data[column]]\n",
    "        \n",
    "    return all_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2e3cda2-729a-48cc-8884-e2d4e122f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "towers_data = tower_dfs_15m_8\n",
    "tower_names = towers_of_interest\n",
    "\n",
    "window_vars = ['TempC', 'RelHum', 'AbsHum', 'WSpdMph', 'PkWSpdMph', 'SolarRadWm2', 'BarPresMb']\n",
    "towers = ['TOWA', 'TOWB', 'TOWD', 'TOWF', 'TOWS', 'TOWY']\n",
    "\n",
    "all_outliers = {}\n",
    "for var in window_vars:\n",
    "    all_outliers[var] = {}\n",
    "    for tower in towers:\n",
    "        multi_tower_outliers = plot_variable_data_for_window_sizes(towers_data, tower_names, var, tower)\n",
    "        all_outliers[var][tower] = multi_tower_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbdb17f-1f92-4099-8333-953332ff3389",
   "metadata": {},
   "source": [
    "### 1(b). Simple non-rolling window variables\n",
    "Sigma, SigPhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1aa32da9-0981-43ca-b32a-030e040e4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_to_nan(data, names, var, tower):\n",
    "    combined_data = extract_variable_data_by_height(towers_data, tower_names)\n",
    "    all_outliers = collections.defaultdict(dict)\n",
    "    for height in set(col.split('_')[1] for col in towers_data[tower_names.index(tower)].columns if col.startswith(var)):\n",
    "        column = f\"{tower}_{height}\"\n",
    "            \n",
    "        group = 'others'\n",
    "        if tower in ['TOWA', 'TOWB', 'TOWD']:\n",
    "            group = 'group1'\n",
    "        elif tower in ['TOWF', 'TOWS']:\n",
    "            group = 'group2'\n",
    "        elif tower == 'TOWY':\n",
    "            group = 'group3'\n",
    "        \n",
    "        key = (var, height, group)\n",
    "        if key not in combined_data:\n",
    "            continue\n",
    "        \n",
    "        data = combined_data[key]\n",
    "        if column not in data.columns:\n",
    "            continue\n",
    "\n",
    "        zero_indices = data[data[column] == 0].index\n",
    "        data = data.replace(0, np.NaN)\n",
    "        all_outliers[height] = [zero_indices, data[column]]\n",
    "\n",
    "    return all_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2b8cab7-5cbf-450e-a4f2-a428c3c4f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 0 to NaN\n",
    "zero_vars = ['Sigma', 'SigPhi']\n",
    "towers = ['TOWA', 'TOWB', 'TOWD', 'TOWF', 'TOWS', 'TOWY']\n",
    "for var in zero_vars:\n",
    "    all_outliers[var] = {}\n",
    "    for tower in towers:\n",
    "        multi_tower_zeros = set_to_nan(towers_data, tower_names, var, tower)\n",
    "        all_outliers[var][tower] = multi_tower_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9851c8-bfba-4a13-9fdd-eeb14fdd84a4",
   "metadata": {},
   "source": [
    "### 1(c) Wind direction clustering [optional; not used here]\n",
    "WDir, WSpdMph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60bd32b8-fdb9-4471-bb01-49d33d8609aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_cartesian_coordinates(wind_speed, wind_dir_deg):\n",
    "#     wind_dir_rad = np.deg2rad(wind_dir_deg)\n",
    "#     U = (-wind_speed * np.sin(wind_dir_rad)).astype(np.float32)  # Negative sign to align with meteorological convention\n",
    "#     V = (-wind_speed * np.cos(wind_dir_rad)).astype(np.float32)  # Negative sign to align with meteorological convention\n",
    "#     return U, V\n",
    "\n",
    "# def plot_wind_data(towers_data, data_dict, var='WSpdMph', eps=0.95, min_samples=2, tower_groups=None):\n",
    "#     if tower_groups is None:\n",
    "#         tower_groups = {\n",
    "#             'group1': ['TOWA', 'TOWB', 'TOWD'],\n",
    "#             'group2': ['TOWF', 'TOWS'],\n",
    "#             'group3': ['TOWY']\n",
    "#         }\n",
    "\n",
    "#     true_wdir_outliers = defaultdict(list)\n",
    "\n",
    "#     for tower, heights in data_dict[var].items():\n",
    "\n",
    "#         # Determine the group based on tower name\n",
    "#         group = 'others'\n",
    "#         for g, towers_in_group in tower_groups.items():\n",
    "#             if tower in towers_in_group:\n",
    "#                 group = g\n",
    "#                 break\n",
    "\n",
    "#         print(f'Working on tower {tower} in {group}')\n",
    "\n",
    "#         for height, (datetime_indices_wspd, wspd_series) in heights.items():\n",
    "\n",
    "#             # Initialize the outlier list for this tower-height combination\n",
    "#             true_wdir_outliers[(tower, height)] = []\n",
    "\n",
    "#             wspd_column = f'{var}_{height}'\n",
    "\n",
    "#             tower_df = None\n",
    "#             for df in towers_data:\n",
    "#                 if wspd_column in df.columns:\n",
    "#                     tower_df = df\n",
    "#                     break\n",
    "            \n",
    "#             if tower_df is not None and var in data_dict and tower in data_dict[var] and height in data_dict[var][tower]:\n",
    "\n",
    "#                 wdir_column = f'WDir_{height}'\n",
    "                \n",
    "#                 wspd_data = data_dict[var][tower][height][1]\n",
    "#                 wdir_data = tower_df[wdir_column]\n",
    "\n",
    "#                 # Calculate Cartesian coordinates\n",
    "#                 U, V = calculate_cartesian_coordinates(wspd_data, wdir_data)\n",
    "                \n",
    "#                 # Remove rows with NaN values\n",
    "#                 nan_indices = np.isnan(U) | np.isnan(V)\n",
    "#                 U_clean = U[~nan_indices]\n",
    "#                 V_clean = V[~nan_indices]\n",
    "                \n",
    "#                 # Perform DBSCAN clustering\n",
    "#                 X = np.column_stack((U_clean, V_clean))\n",
    "#                 clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "                \n",
    "#                 # Detect outliers\n",
    "#                 outlier_indices = clustering.labels_ == -1  # mask, -1 indicates outlier points (True)\n",
    "#                 wdir_data_nonnan = wdir_data[~nan_indices]\n",
    "#                 outlier_dates = wdir_data_nonnan.index[outlier_indices]\n",
    "\n",
    "#                 # Collect outliers in a list\n",
    "#                 outliers_to_add = []\n",
    "#                 for outlier_date in outlier_dates:\n",
    "#                     if outlier_date not in datetime_indices_wspd:\n",
    "#                         outliers_to_add.append(outlier_date)\n",
    "\n",
    "#                 # Append all outliers in one go\n",
    "#                 true_wdir_outliers[(tower, height)].extend(outliers_to_add)\n",
    "#                 del wspd_data, wdir_data, U, V, U_clean, V_clean, X, clustering, outlier_indices, wdir_data_nonnan, outlier_dates, outliers_to_add\n",
    "\n",
    "#     # Check for outliers detected at the same height in different towers of the same group\n",
    "#     group_outliers = defaultdict(list)\n",
    "#     for (tower, height), outliers in true_wdir_outliers.items():\n",
    "#         for group_name, towers_in_group in tower_groups.items():\n",
    "#             if tower in towers_in_group:\n",
    "#                 for other_tower in towers_in_group:\n",
    "#                     if other_tower != tower and (other_tower, height) in true_wdir_outliers:\n",
    "#                         common_outliers = set(outliers) & set(true_wdir_outliers[(other_tower, height)])\n",
    "#                         for outlier_date in common_outliers:\n",
    "#                             group_outliers[(tower, height)].append(outlier_date)\n",
    "#                             group_outliers[(other_tower, height)].append(outlier_date)\n",
    "\n",
    "#     # Remove common outliers from true_wdir_outliers\n",
    "#     for (tower, height), outliers in group_outliers.items():\n",
    "#         true_wdir_outliers[(tower, height)] = [date for date in true_wdir_outliers[(tower, height)] if date not in outliers]\n",
    "\n",
    "#     # print(true_wdir_outliers)\n",
    "#     return true_wdir_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a82b76bb-7542-480a-8c7b-c58a287de06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_wdir_outliers = plot_wind_data(tower_dfs_15m_8, all_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ff9b084-c1a1-4154-8336-46b91f5838b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in true_wdir_outliers:\n",
    "#     true_wdir_outliers[key] = pd.DatetimeIndex(true_wdir_outliers[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5093dd-7266-4537-bd70-5a88d88868d5",
   "metadata": {},
   "source": [
    "### 2. Prep for export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7307be-281c-4587-8954-74d058f89659",
   "metadata": {},
   "source": [
    "#### Wind Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "332cec4d-3d28-4f74-b537-37c4dbae9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_outliers['WDir'] = {}\n",
    "# for (tower, height), datetimeindex in true_wdir_outliers.items():\n",
    "#     all_outliers['WDir'][tower] = {}\n",
    "#     tower_idx = tower_names.index(tower)\n",
    "#     df = tower_dfs_15m_8[tower_idx]\n",
    "#     column_name = f'WDir_{height}'\n",
    "    \n",
    "#     if column_name in df.columns:\n",
    "#         wdir_series = df[column_name]\n",
    "#         # Store the pandas Series in the appropriate place\n",
    "#         all_outliers['WDir'][tower][height] = [datetimeindex, wdir_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da8946-3027-4d1f-a9f7-efc5703a2ef2",
   "metadata": {},
   "source": [
    "#### VSSpdMph and PrecipIn (and WDir if not doing clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "340aa13f-3d0e-4f17-ac77-c9b2dfd9dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to process\n",
    "vars_to_process = ['VSSpdMph', 'PrecipIn', 'WDir']\n",
    "\n",
    "# Add variables to all_outliers\n",
    "for var in vars_to_process:\n",
    "    all_outliers[var] = {}\n",
    "    for tower, df in zip(tower_names, tower_dfs_15m_8):\n",
    "        all_outliers[var][tower] = {}\n",
    "        for column_name in df.columns:\n",
    "            if var in column_name:\n",
    "                height = column_name.split('_')[-1]  # Extract height from column name\n",
    "                var_series = df[column_name]\n",
    "                \n",
    "                # Store the pandas Series in the appropriate place\n",
    "                all_outliers[var][tower][height] = [None, var_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a97981a-fecc-4b7d-a626-77da835a92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = {}\n",
    "vars = ['TempC',\n",
    "        'RelHum', 'AbsHum', \n",
    "        'WSpdMph', 'PkWSpdMph', 'VSSpdMph',\n",
    "        'SolarRadWm2', \n",
    "        'BarPresMb',\n",
    "        'Sigma', 'SigPhi',\n",
    "        'WDir',\n",
    "        'PrecipIn']\n",
    "\n",
    "for var in vars:\n",
    "    cleaned_data[var] = {}\n",
    "    for tower in towers:\n",
    "        cleaned_data[var][tower] = {}\n",
    "        heights = list(all_outliers[var][tower].keys())\n",
    "        for height in heights:\n",
    "            outliers = all_outliers[var][tower][height][0]\n",
    "            data = all_outliers[var][tower][height][1]\n",
    "            data.loc[outliers] = np.nan\n",
    "            cleaned_data[var][tower][height] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7976b116-fbeb-4a83-a876-45abb6874f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting list of dataframes\n",
    "tower_dfs_15m_9 = []\n",
    "toi = []\n",
    "\n",
    "# Extract towers\n",
    "towers = set()\n",
    "for var in cleaned_data:\n",
    "    towers.update(cleaned_data[var].keys())\n",
    "\n",
    "# Iterate over each tower\n",
    "for tower in towers:\n",
    "    combined_data = {}\n",
    "    for var in cleaned_data:\n",
    "        if tower in cleaned_data[var]:\n",
    "            for height in cleaned_data[var][tower]:\n",
    "                column_name = f\"{var}_{height}\"\n",
    "                series = cleaned_data[var][tower][height]\n",
    "                combined_data[column_name] = series\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "    tower_dfs_15m_9.append((tower, combined_df))\n",
    "\n",
    "tower_dfs_15m_9 = sorted(tower_dfs_15m_9, key=lambda x: x[0])\n",
    "tower_dfs_15m_9 = [x[1] for x in tower_dfs_15m_9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228cc56-ce92-433f-8848-af25e5b9ef19",
   "metadata": {},
   "source": [
    "### 3. Export files and perform manual checks\n",
    "The rolling window approach was fairly accurate but missed a LOT of outliers; so I had to take a manual approach to remove outliers afterward\n",
    "1. Using a dashboard, I interactively visualized the data over time as line graphs\n",
    "2. Working through each Tower's VariableNameUnit_Height{m}, I visually identified outliers by comparing one line to all the others\n",
    "3. When clicking on a point, the datetime is outputted on the screen in a way that I could copy and paste it into a csv.\n",
    "4. The csv contained a start_datetime and end_datetime column, which I populated with the copied and pasted dates (if only one point was an outlier, I only populated the start_datetime; if the outlier was consecutive over time, I provided the start and end datetime of the consecutive outliers)\n",
    "5. Outliers could be large jumps in the data (those that don't correspond with jumps occuring at the same time as other towers; those are likely real jumps), brief periods of identical values, or visual strangeness (magnitude smaller or larger variations, stair-stepping, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e517fbf4-cba7-412f-b9e5-842c86a3bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datetimes\n",
    "tower_dfs_15m_10 = []\n",
    "for df, tower in zip(tower_dfs_15m_9, towers_of_interest):\n",
    "    df.index.name = 'datetimeET'\n",
    "    df.index = df.index.tz_localize('US/Eastern', ambiguous='NaT', nonexistent='NaT')\n",
    "    df = df[df.index.notna()]\n",
    "    df['timestampUTC'] = df.index.tz_convert('UTC').strftime('%Y%m%d%H%M%S')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.set_index('timestampUTC')\n",
    "    \n",
    "    # No fillna(-999) here, let NaNs remain intact for outlier removal\n",
    "    df = df.astype('float32')\n",
    "    tower_dfs_15m_10.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b45d6-6f90-4718-9706-e321096e65fc",
   "metadata": {},
   "source": [
    "### 4. Remove manually identified outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c167b65-5a16-4405-ad8b-9ae8a4f454af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOWA\n",
      "TOWB\n",
      "TOWD\n",
      "TOWF\n",
      "TOWS\n",
      "TOWY\n"
     ]
    }
   ],
   "source": [
    "# List to store the modified dataframes\n",
    "tower_dfs_15m_clean = []\n",
    "\n",
    "# Timezone objects\n",
    "et = timezone('US/Eastern')\n",
    "utc = timezone('UTC')\n",
    "\n",
    "# Function to set values to NaN based on datetime ranges\n",
    "def set_nan_in_dataframe(df, ranges):\n",
    "    df2 = df.copy()\n",
    "    for _, row in ranges.iterrows():\n",
    "        start = row['datetime_start']\n",
    "        finish = row['datetime_end'] if pd.notnull(row['datetime_end']) else start\n",
    "        column = row['column']\n",
    "\n",
    "        # Skip rows with invalid datetime or missing column\n",
    "        if pd.isna(start):\n",
    "            print(\"Skipping row with missing datetime_start:\")\n",
    "            print(row)\n",
    "            continue\n",
    "        if column not in df2.columns:\n",
    "            # print(f\"Column '{column}' not found in DataFrame. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Format strings to match df index\n",
    "        start_str = start.strftime('%Y%m%d%H%M%S')\n",
    "        finish_str = finish.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "        # Assign NaN\n",
    "        df2.loc[start_str:finish_str, column] = np.nan\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "# Iterate through each tower of interest\n",
    "for tower, tower_df_15m in zip(towers_of_interest, tower_dfs_15m_10):\n",
    "    print(tower)\n",
    "    \n",
    "    # Construct the filename\n",
    "    file_path = f\"../data/met_towers_2017-2022_manual-outlier-id/{tower}_2017-2022_manual-outlier-id.csv\"\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # Load the CSV into a dataframe\n",
    "        tower_outliers = pd.read_csv(\n",
    "            file_path,\n",
    "            header=0,\n",
    "            parse_dates=['datetime_start', 'datetime_end']\n",
    "        )\n",
    "        \n",
    "        # Extract datetime ranges and corresponding columns\n",
    "        ranges = tower_outliers[['datetime_start', 'datetime_end', 'column']]\n",
    "        \n",
    "        # Convert the \"datetime_start\" and \"datetime_end\" to datetime and localize to ET, then convert to UTC\n",
    "        ranges['datetime_start'] = (\n",
    "            pd.to_datetime(ranges['datetime_start'], format='mixed', errors='coerce')\n",
    "            .dt.tz_localize(et, ambiguous='NaT')  # Localize to ET\n",
    "            .dt.tz_convert(utc)  # Convert to UTC\n",
    "        )\n",
    "        ranges['datetime_end'] = (\n",
    "            pd.to_datetime(ranges['datetime_end'], format='mixed', errors='coerce')\n",
    "            .dt.tz_localize(et, ambiguous='NaT')  # Localize to ET\n",
    "            .dt.tz_convert(utc)  # Convert to UTC\n",
    "        )\n",
    "\n",
    "        # Ensure the tower_df_15m index is aligned with the desired format\n",
    "        if not pd.api.types.is_datetime64_any_dtype(tower_df_15m.index):\n",
    "            tower_df_15m.index = pd.to_datetime(tower_df_15m.index, format='%Y%m%d%H%M%S').tz_localize(utc)\n",
    "\n",
    "        # Convert index back to string format YYYYMMDDHHMMSS\n",
    "        tower_df_15m.index = tower_df_15m.index.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "        # Set the appropriate values to NaN\n",
    "        tower_df_outliers_removed = set_nan_in_dataframe(tower_df_15m, ranges)\n",
    "        \n",
    "        # Append the modified dataframe to the list\n",
    "        tower_dfs_15m_clean.append(tower_df_outliers_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c6530a4-0c23-4c7f-942b-07d37f95c8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempC_015m</th>\n",
       "      <th>TempC_030m</th>\n",
       "      <th>RelHum_015m</th>\n",
       "      <th>AbsHum_015m</th>\n",
       "      <th>WSpdMph_015m</th>\n",
       "      <th>WSpdMph_030m</th>\n",
       "      <th>PkWSpdMph_015m</th>\n",
       "      <th>PkWSpdMph_030m</th>\n",
       "      <th>VSSpdMph_015m</th>\n",
       "      <th>VSSpdMph_030m</th>\n",
       "      <th>BarPresMb_015m</th>\n",
       "      <th>Sigma_015m</th>\n",
       "      <th>Sigma_030m</th>\n",
       "      <th>SigPhi_015m</th>\n",
       "      <th>SigPhi_030m</th>\n",
       "      <th>WDir_015m</th>\n",
       "      <th>WDir_030m</th>\n",
       "      <th>PrecipIn_015m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestampUTC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20170101050000</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.299988</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>15.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>12.6</td>\n",
       "      <td>268.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170101051500</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>97.300003</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>985.299988</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>252.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170101053000</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>985.200012</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TempC_015m  TempC_030m  RelHum_015m  AbsHum_015m  \\\n",
       "timestampUTC                                                       \n",
       "20170101050000         3.6         3.6    97.400002          6.0   \n",
       "20170101051500         3.6         3.6    97.300003          6.0   \n",
       "20170101053000         3.6         3.7    97.400002          6.0   \n",
       "\n",
       "                WSpdMph_015m  WSpdMph_030m  PkWSpdMph_015m  PkWSpdMph_030m  \\\n",
       "timestampUTC                                                                 \n",
       "20170101050000           2.2           4.4             5.9            10.2   \n",
       "20170101051500           2.4           4.7             6.7             7.7   \n",
       "20170101053000           2.8           4.3             6.0             6.8   \n",
       "\n",
       "                VSSpdMph_015m  VSSpdMph_030m  BarPresMb_015m  Sigma_015m  \\\n",
       "timestampUTC                                                               \n",
       "20170101050000            0.0      -0.100000      985.299988   26.500000   \n",
       "20170101051500            0.0      -0.100000      985.299988   19.299999   \n",
       "20170101053000           -0.2       0.000064      985.200012   25.299999   \n",
       "\n",
       "                Sigma_030m  SigPhi_015m  SigPhi_030m  WDir_015m  WDir_030m  \\\n",
       "timestampUTC                                                                 \n",
       "20170101050000        15.5         18.9         12.6      268.0      274.0   \n",
       "20170101051500        13.9         14.3          9.8      252.0      264.0   \n",
       "20170101053000        15.0         13.6         11.0      255.0      260.0   \n",
       "\n",
       "                PrecipIn_015m  \n",
       "timestampUTC                   \n",
       "20170101050000       0.015748  \n",
       "20170101051500       0.011811  \n",
       "20170101053000       0.011811  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_15m_clean[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "947d0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AbsHum_015m', 'BarPresMb_015m', 'PkWSpdMph_015m', 'PkWSpdMph_030m',\n",
       "       'RelHum_015m', 'Sigma_015m', 'Sigma_030m', 'SigPhi_015m', 'SigPhi_030m',\n",
       "       'TempC_015m', 'TempC_030m', 'VSSpdMph_015m', 'VSSpdMph_030m',\n",
       "       'WDir_015m', 'WDir_030m', 'WSpdMph_015m', 'WSpdMph_030m',\n",
       "       'PrecipIn_015m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tower_dfs_15m_4[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d599ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0966052200077758\n",
      "19.70653832175398\n",
      "4.208521467692509\n",
      "16.26984126984127\n",
      "0.17353187281302299\n",
      "0.3034034433794817\n"
     ]
    }
   ],
   "source": [
    "preremoval = []\n",
    "for df, tower in zip(tower_dfs_15m_4, towers_of_interest):\n",
    "    nan_percentage = (df.isna().sum() / len(df)) * 100\n",
    "    preremoval.append(nan_percentage)\n",
    "    print(nan_percentage.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90638f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585623177197651\n",
      "19.77427229213648\n",
      "4.45699724048279\n",
      "16.315761531890885\n",
      "0.17814948664014682\n",
      "0.3321125410914654\n"
     ]
    }
   ],
   "source": [
    "autoremoval = []\n",
    "for df, tower in zip(tower_dfs_15m_9, towers_of_interest):\n",
    "    nan_percentage = (df.isna().sum() / len(df)) * 100\n",
    "    autoremoval.append(nan_percentage)\n",
    "    print(nan_percentage.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d075cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9742015183409847\n",
      "20.09780766271864\n",
      "4.566679302398888\n",
      "19.811005224580892\n",
      "0.17092205519505224\n",
      "0.3224942301351797\n"
     ]
    }
   ],
   "source": [
    "manremoval = []\n",
    "for df, tower in zip(tower_dfs_15m_clean, towers_of_interest):\n",
    "    nan_percentage = (df.isna().sum() / len(df)) * 100\n",
    "    manremoval.append(nan_percentage)\n",
    "    print(nan_percentage.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d4ee8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOWA: 1.0966052200077758\n",
      "TOWB: 19.70653832175398\n",
      "TOWD: 4.208521467692509\n",
      "TOWF: 16.26984126984127\n",
      "TOWS: 0.17353187281302299\n",
      "TOWY: 0.3034034433794817\n",
      "TOWA: 1.2585623177197651\n",
      "TOWB: 19.77427229213648\n",
      "TOWD: 4.45699724048279\n",
      "TOWF: 16.315761531890885\n",
      "TOWS: 0.17814948664014682\n",
      "TOWY: 0.3321125410914654\n",
      "TOWA: 2.9742015183409847\n",
      "TOWB: 20.09780766271864\n",
      "TOWD: 4.566679302398888\n",
      "TOWF: 19.811005224580892\n",
      "TOWS: 0.17092205519505224\n",
      "TOWY: 0.3224942301351797\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step 1 - No Removal</th>\n",
       "      <th>Step 2 - Automated Removal</th>\n",
       "      <th>Step 3 - Manual Removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOWA</th>\n",
       "      <td>1.096605</td>\n",
       "      <td>1.258562</td>\n",
       "      <td>2.974202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOWB</th>\n",
       "      <td>19.706538</td>\n",
       "      <td>19.774272</td>\n",
       "      <td>20.097808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOWD</th>\n",
       "      <td>4.208521</td>\n",
       "      <td>4.456997</td>\n",
       "      <td>4.566679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOWF</th>\n",
       "      <td>16.269841</td>\n",
       "      <td>16.315762</td>\n",
       "      <td>19.811005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOWS</th>\n",
       "      <td>0.173532</td>\n",
       "      <td>0.178149</td>\n",
       "      <td>0.170922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOWY</th>\n",
       "      <td>0.303403</td>\n",
       "      <td>0.332113</td>\n",
       "      <td>0.322494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Step 1 - No Removal  Step 2 - Automated Removal  Step 3 - Manual Removal\n",
       "TOWA             1.096605                    1.258562                 2.974202\n",
       "TOWB            19.706538                   19.774272                20.097808\n",
       "TOWD             4.208521                    4.456997                 4.566679\n",
       "TOWF            16.269841                   16.315762                19.811005\n",
       "TOWS             0.173532                    0.178149                 0.170922\n",
       "TOWY             0.303403                    0.332113                 0.322494"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate NaN percentage per dataframe\n",
    "def calculate_nan_percentage(df):\n",
    "    return (df.isna().sum() / len(df)) * 100\n",
    "\n",
    "# Step 1: Get the union of all columns across the three sets of dataframes\n",
    "all_columns = set()\n",
    "\n",
    "# Get the columns from all dataframes at all steps\n",
    "for df in tower_dfs_15m_4 + tower_dfs_15m_9 + tower_dfs_15m_clean:\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "# Convert to a sorted list to maintain consistent column order\n",
    "all_columns = sorted(all_columns)\n",
    "\n",
    "# For Pre-removal step\n",
    "preremoval = []\n",
    "for df, tower in zip(tower_dfs_15m_4, towers_of_interest):\n",
    "    df_sorted = df.reindex(columns=df.columns.intersection(all_columns))  # Align columns to the intersection of existing columns\n",
    "    nan_percentage = calculate_nan_percentage(df_sorted)\n",
    "    preremoval.append(nan_percentage)\n",
    "    print(f\"{tower}: {nan_percentage.mean()}\")  # Print the mean NaN percentage per tower\n",
    "\n",
    "# For Automated removal step\n",
    "autoremoval = []\n",
    "for df, tower in zip(tower_dfs_15m_9, towers_of_interest):\n",
    "    df_sorted = df.reindex(columns=df.columns.intersection(all_columns))  # Align columns to the intersection of existing columns\n",
    "    nan_percentage = calculate_nan_percentage(df_sorted)\n",
    "    autoremoval.append(nan_percentage)\n",
    "    print(f\"{tower}: {nan_percentage.mean()}\")  # Print the mean NaN percentage per tower\n",
    "\n",
    "# For Manual removal step\n",
    "manremoval = []\n",
    "for df, tower in zip(tower_dfs_15m_clean, towers_of_interest):\n",
    "    df_sorted = df.reindex(columns=df.columns.intersection(all_columns))  # Align columns to the intersection of existing columns\n",
    "    nan_percentage = calculate_nan_percentage(df_sorted)\n",
    "    manremoval.append(nan_percentage)\n",
    "    print(f\"{tower}: {nan_percentage.mean()}\")  # Print the mean NaN percentage per tower\n",
    "\n",
    "# Combine the results into a DataFrame for easy comparison\n",
    "preremoval_df = pd.DataFrame(preremoval, columns=all_columns, index=towers_of_interest)\n",
    "autoremoval_df = pd.DataFrame(autoremoval, columns=all_columns, index=towers_of_interest)\n",
    "manremoval_df = pd.DataFrame(manremoval, columns=all_columns, index=towers_of_interest)\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "nan_percent_df = pd.DataFrame({\n",
    "    'Step 1 - No Removal': preremoval_df.mean(axis=1),\n",
    "    'Step 2 - Automated Removal': autoremoval_df.mean(axis=1),\n",
    "    'Step 3 - Manual Removal': manremoval_df.mean(axis=1)\n",
    "})\n",
    "nan_percent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c376a8-3582-4775-8784-be80b6f80977",
   "metadata": {},
   "source": [
    "### 5. Export quality assessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd90d6b9-7c5d-4ae0-ba38-484fcaa112fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, tower in zip(tower_dfs_15m_clean, towers_of_interest):\n",
    "    output_dir = '../data/met_towers_2017-2022_final-qc'\n",
    "    os.makedirs(output_dir, exist_ok=True)   # ← create it if it doesn’t exist\n",
    "    \n",
    "    # now it will succeed\n",
    "    df = df.fillna(-999).astype('float32')\n",
    "    df.to_csv(\n",
    "        os.path.join(output_dir, f'{tower}_2017-2022_final-qc.csv'),\n",
    "        encoding='utf-8-sig'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71cbea-9dd5-4c5c-a2d2-8ea2a5bc02a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
